{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"tree_data_training\")\n",
    "TREE_DATA = Path(\"final_data/trees/\")\n",
    "\n",
    "FEATURE_COLS = ['has_tree', 'avg_height', 'avg_year', 'temperature_2m', 'relative_humidity_2m', 'dew_point_2m',\n",
    "       'apparent_temperature', 'precipitation', 'rain', 'snowfall',\n",
    "       'snow_depth', 'weather_code', 'pressure_msl', 'surface_pressure',\n",
    "       'wind_speed_10m', 'wind_direction_10m', 'wind_gusts_10m',\n",
    "       'average_soil_moisture', 'average_soil_temperature', 'num_trees']\n",
    "\n",
    "FINAL_COLS = ['avg_height', 'avg_year', 'apparent_temperature', 'rain', 'wind_speed_10m', 'wind_gusts_10m', 'num_trees', 'Fraxinus', 'Salix', 'Alnus', 'Quercus', 'Tilia', 'Acer', 'Populus', 'Betula', 'Prunus', 'Platanus', 'Malus', 'Robinia', 'Crataegus',\n",
    "       'Ulmus', 'Carpinus', 'Overig', 'Onbekend']\n",
    "\n",
    "TREE_NAMES = ['Fraxinus', 'Salix', 'Alnus', 'Quercus', 'Tilia', 'Acer', 'Populus', 'Betula', 'Prunus', 'Platanus', 'Malus', 'Robinia', 'Crataegus',\n",
    "       'Ulmus', 'Carpinus', 'Overig', 'Onbekend']\n",
    "\n",
    "TEST_PERCENTAGE = 0.2 # percentage of total\n",
    "VALIDATION_PERCENTAGE = 0.25 # percentage of (1-TEST_PERCENTAGE)*total\n",
    "ID_KEY = \"Incident_ID\"\n",
    "LABEL_KEY = \"Label\"\n",
    "\n",
    "SOIL_MOISTURE_COLUMNS = [\n",
    "    'soil_moisture_0_to_7cm',\n",
    "    'soil_moisture_7_to_28cm', \n",
    "    'soil_moisture_28_to_100cm', \n",
    "    'soil_moisture_100_to_255cm'\n",
    "]\n",
    "\n",
    "SOIL_TEMPERATURE_COLUMNS = [\n",
    "    'soil_temperature_0_to_7cm',\n",
    "    'soil_temperature_7_to_28cm',\n",
    "    'soil_temperature_28_to_100cm',\n",
    "    'soil_temperature_100_to_255cm',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in training and testing sets\n",
    "positive_path = TREE_DATA / \"trees_new_grid_pos_samples.csv\"\n",
    "negative_path_t = TREE_DATA / \"trees_new_grid_neg_samples_true.csv\"\n",
    "negative_path_f = TREE_DATA / \"trees_new_grid_neg_samples_false.csv\" \n",
    "negative_path_r = TREE_DATA / \"trees_new_grid_neg_samples_random.csv\" \n",
    "\n",
    "positive_samples_df = pd.read_csv(positive_path, sep=\",\", encoding=\"utf-8\")\n",
    "negative_samples_df_t = pd.read_csv(negative_path_t, sep=\",\", encoding=\"utf-8\")\n",
    "negative_samples_df_f = pd.read_csv(negative_path_f, sep=\",\", encoding=\"utf-8\")\n",
    "negative_samples_df_r = pd.read_csv(negative_path_r, sep=\",\", encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_samples_df = pd.concat([negative_samples_df_t, negative_samples_df_f, negative_samples_df_r], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "has_tree\n",
       "False    2387\n",
       "True     2107\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_samples_df.has_tree.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure both df's have identifiable id\n",
    "# Not really necessary but makes things easier\n",
    "positive_samples_df[ID_KEY] = [\"P\"+str(id_) for id_ in positive_samples_df['Incident_ID']]\n",
    "negative_samples_df[ID_KEY] = [\"N\"+str(id_) for id_ in range(len(negative_samples_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels\n",
    "positive_samples_df[LABEL_KEY] = 1\n",
    "negative_samples_df[LABEL_KEY] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_samples_df = positive_samples_df.fillna(0)\n",
    "negative_samples_df = negative_samples_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df's\n",
    "pos_columns = positive_samples_df.columns\n",
    "neg_columns = negative_samples_df.columns\n",
    "common_cols = pos_columns.intersection(neg_columns)\n",
    "\n",
    "positive_sub_df = positive_samples_df[common_cols]\n",
    "negative_sub_df = negative_samples_df[common_cols]\n",
    "\n",
    "tree_training_df = pd.concat([positive_sub_df, negative_sub_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_across_cols(\n",
    "    df,\n",
    "    cols,\n",
    "    new_col\n",
    "):\n",
    "    df[new_col] = df[cols].mean(axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_training_df = average_across_cols(tree_training_df, SOIL_MOISTURE_COLUMNS, \"average_soil_moisture\")\n",
    "tree_training_df = average_across_cols(tree_training_df, SOIL_TEMPERATURE_COLUMNS, \"average_soil_temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tree_training_df.drop(col, axis=1, inplace=True) for col in SOIL_MOISTURE_COLUMNS]\n",
    "[tree_training_df.drop(col, axis=1, inplace=True) for col in SOIL_TEMPERATURE_COLUMNS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create num trees col\n",
    "tree_names = ['Fraxinus', 'Salix', 'Alnus', 'Quercus', 'Tilia', 'Acer', 'Populus',\n",
    "       'Betula', 'Prunus', 'Platanus', 'Malus', 'Robinia', 'Crataegus',\n",
    "       'Ulmus', 'Carpinus', 'Overig', 'Onbekend']\n",
    "tree_training_df['num_trees'] = tree_training_df[tree_names].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_test(\n",
    "    df,\n",
    "    seed = 42,\n",
    "    feature_cols = FEATURE_COLS\n",
    "):\n",
    "    train_ids, test_ids, train_labels, test_labels = train_test_split(df[ID_KEY], df[LABEL_KEY], test_size=TEST_PERCENTAGE, stratify=df[LABEL_KEY], random_state=seed)\n",
    "    \n",
    "    feature_cols = [col for col in feature_cols if col not in SOIL_MOISTURE_COLUMNS and col not in SOIL_TEMPERATURE_COLUMNS]\n",
    "    print(f\"Using feature cols {feature_cols}\")\n",
    "    \n",
    "    train_set = df[df[ID_KEY].isin(train_ids)]\n",
    "    test_set = df[df[ID_KEY].isin(test_ids)]\n",
    "\n",
    "    x_train = train_set[feature_cols]\n",
    "    y_train = train_set[LABEL_KEY]\n",
    "    x_test = test_set[feature_cols]\n",
    "    y_test = test_set[LABEL_KEY]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf  = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "x_train, y_train, x_test, y_test = make_train_test(tree_training_df, feature_cols=FEATURE_COLS, seed = 42)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "pred = clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = XGBClassifier(verbosity=2, max_depth=15, subsample=0.9)\n",
    "import xgboost\n",
    "\n",
    "cols = ['has_tree', 'avg_height', 'avg_year', 'temperature_2m', 'relative_humidity_2m', 'dew_point_2m',\n",
    "       'apparent_temperature', 'precipitation', 'rain', 'snowfall',\n",
    "       'snow_depth', 'weather_code', 'pressure_msl', 'surface_pressure',\n",
    "       'wind_speed_10m', 'wind_direction_10m', 'wind_gusts_10m',\n",
    "       'average_soil_moisture', 'average_soil_temperature', 'num_trees']\n",
    "\n",
    "best_cols = ['avg_height', 'avg_year', 'apparent_temperature', 'rain', 'wind_speed_10m', 'wind_gusts_10m', 'num_trees', 'Fraxinus', 'Salix', 'Alnus', 'Quercus', 'Tilia', 'Acer', 'Populus', 'Betula', 'Prunus', 'Platanus', 'Malus', 'Robinia', 'Crataegus',\n",
    "       'Ulmus', 'Carpinus', 'Overig', 'Onbekend']\n",
    "\n",
    "tree_names = ['Fraxinus', 'Salix', 'Alnus', 'Quercus', 'Tilia', 'Acer', 'Populus', 'Betula', 'Prunus', 'Platanus', 'Malus', 'Robinia', 'Crataegus',\n",
    "       'Ulmus', 'Carpinus', 'Overig', 'Onbekend']\n",
    "\n",
    "# test_cols += tree_names\n",
    "\n",
    "x_train, y_train, x_test, y_test = make_train_test(tree_training_df, feature_cols=best_cols,  seed=42)\n",
    "\n",
    "d_train = xgboost.DMatrix(x_train, label=y_train)\n",
    "d_test = xgboost.DMatrix(x_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    \"eta\": 0.01,\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"subsample\": 0.5,\n",
    "    \"base_score\": np.mean(y_train),\n",
    "    \"eval_metric\": \"logloss\",\n",
    "}\n",
    "model = xgboost.train(\n",
    "    params,\n",
    "    d_train,\n",
    "    5000,\n",
    "    evals=[(d_test, \"test\")],\n",
    "    verbose_eval=100,\n",
    "    early_stopping_rounds=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(xgboost.DMatrix(x_test), )\n",
    "preds_t = [1 if pred >= 0.5 else 0 for pred in preds]\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "xgboost.plot_importance(model, importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, 15, 20, 25, None],\n",
    "    'subsample': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "clf = XGBClassifier()\n",
    "\n",
    "\n",
    "x_train, y_train, x_test, y_test = make_train_test(tree_training_df, feature_cols=FINAL_COLS,  seed = 42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='accuracy', cv=3, verbose=3)\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(x_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Best Model Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(verbosity=2, max_depth=20, subsample=0.7)\n",
    "\n",
    "x_train, y_train, x_test, y_test = make_train_test(tree_training_df, feature_cols=FINAL_COLS)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "predictions = clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#save model\n",
    "with open(\"models/trees/xgboost_new_md20_sub70_tfr_bc.pkl\", \"wb\") as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "clf = LogisticRegression()\n",
    "\n",
    "x_train, y_train, x_test, y_test = make_train_test(tree_training_df, feature_cols=cols, seed = 42)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "predictions = clf.predict(x_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "x_train, y_train, x_test, y_test = make_train_test(tree_training_df, feature_cols=best_cols, seed = 42)\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_clf = SVC(kernel='linear')  # You can choose different kernels like 'linear', 'rbf', 'poly', etc.\n",
    "\n",
    "# Train the classifier\n",
    "svm_clf.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm_clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_gdf = pd.read_csv(\"final_data/grids/grids_enriched_NEW.csv\", sep=\",\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TreeInference import makeTreePrediction\n",
    "from pathlib import Path\n",
    "\n",
    "predictor = makeTreePrediction(model_name=\"xgboost_new_md20_sub70_tfr_bc.pkl\", grid_df=grid_gdf, hours_to_predict=8)\n",
    "pred_dict = predictor.get_predictions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fundamentals-data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

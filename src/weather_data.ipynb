{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from geopy.geocoders import Nominatim\n",
    "from tqdm import tqdm\n",
    "from geopy.distance import geodesic\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import math\n",
    "import datetime\n",
    "import geopandas as gpd\n",
    "import urllib.request\n",
    "import requests\n",
    "import json\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "from shapely.geometry import Polygon, Point\n",
    "from retry_requests import retry\n",
    "from shapely.wkt import loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SPLITS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid df\n",
    "# sample df\n",
    "\n",
    "grids = pd.read_csv(\"data_bomen/grid_enriched_200.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "samples = pd.read_csv(\"data_bomen/negative_samples_200.csv\", sep=\",\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Reimer/opt/anaconda3/envs/fundamentals-data-science/lib/python3.11/site-packages/geopandas/geoseries.py:645: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  result = super().apply(func, convert_dtype=convert_dtype, args=args, **kwargs)\n",
      "/Users/Reimer/opt/anaconda3/envs/fundamentals-data-science/lib/python3.11/site-packages/geopandas/geoseries.py:645: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  result = super().apply(func, convert_dtype=convert_dtype, args=args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "grids['geometry'] = grids['geometry'].apply(lambda x: loads(x))\n",
    "grids_gdf = gpd.GeoDataFrame(grids, geometry='geometry')\n",
    "\n",
    "grids_gdf['centroid'] = grids_gdf['geometry'].centroid\n",
    "grids_gdf['middle_lat'] = grids_gdf['centroid'].apply(lambda point: point.y)\n",
    "grids_gdf['middle_lon'] = grids_gdf['centroid'].apply(lambda point: point.x)\n",
    "\n",
    "negative_samples = samples.merge(grids_gdf[['middle_lat', 'middle_lon']], left_on='grid_id', right_index=True)\n",
    "\n",
    "negative_samples.rename(columns={'middle_lat': 'LAT', 'middle_lon': 'LON'}, inplace=True)\n",
    "columns_order = ['Date', 'grid_id', 'LAT', 'LON'] + [col for col in negative_samples.columns if col not in ['Date', 'grid_id', 'LAT', 'LON']]\n",
    "negative_samples = negative_samples[columns_order]\n",
    "\n",
    "negative_samples = negative_samples.drop('Unnamed: 0', axis=1, errors='ignore')\n",
    "\n",
    "negative_samples = negative_samples.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Open-Meteo API client with cache and retry on error\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after = -1)\n",
    "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "openmeteo = openmeteo_requests.Client(session = retry_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_data(df_split):\n",
    "    # NOTE: order of weather vars matters for retrieving correct data from API\n",
    "    # TODO: check: what does api do when nothing available? NAN? and necessary to set up connection for every df split?\n",
    "    weather_variables = [\n",
    "        temperature_2m_list = [],\n",
    "        relative_humidity_2m_list = [],\n",
    "        dew_point_2m_list = [],\n",
    "        apparent_temperature_list = [],\n",
    "        precipitation_list = [],\n",
    "        rain_list = [],\n",
    "        snowfall_list = [],\n",
    "        snow_depth_list = [],\n",
    "        weather_code_list = [],\n",
    "        pressure_msl_list = [],\n",
    "        surface_pressure_list = [],\n",
    "        cloud_cover_list = [],\n",
    "        cloud_cover_low_list = [],\n",
    "        cloud_cover_mid_list = [],\n",
    "        cloud_cover_high_list = [],\n",
    "        et0_fao_evapotranspiration_list = [],\n",
    "        vapour_pressure_deficit_list = [],\n",
    "        wind_speed_10m_list = [],\n",
    "        wind_speed_100m_list = [],\n",
    "        wind_direction_10m_list = [],\n",
    "        wind_direction_100m_list = [],\n",
    "        wind_gusts_10m_list = [],\n",
    "        soil_temperature_0_to_7cm_list = [],\n",
    "        soil_temperature_7_to_28cm_list = [],\n",
    "        soil_temperature_28_to_100cm_list = [],\n",
    "        soil_temperature_100_to_255cm_list = [],\n",
    "        soil_moisture_0_to_7cm_list = [],\n",
    "        soil_moisture_7_to_28cm_list = [],\n",
    "        soil_moisture_28_to_100cm_list = [],\n",
    "        soil_moisture_100_to_255cm_list = []\n",
    "    ]\n",
    "\n",
    "    cache_session = requests_cache.CachedSession('.cache', expire_after = -1)\n",
    "    retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "    openmeteo = openmeteo_requests.Client(session = retry_session)\n",
    "    for i, row in df_split.iterrows():\n",
    "        latitude = row['LAT']\n",
    "        longitude = row['LON']\n",
    "        dateStr = row['Date']\n",
    "        timeStr = row['Hour']\n",
    "\n",
    "        latitude='{:.5f}'.format(latitude)\n",
    "        longitude='{:.5f}'.format(longitude)\n",
    "\n",
    "        url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "        params = {\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude,\n",
    "            \"start_date\": dateStr,\n",
    "            \"end_date\": dateStr,\n",
    "            \"hourly\": [\"temperature_2m\", \"relative_humidity_2m\", \"dew_point_2m\", \"apparent_temperature\", \"precipitation\", \"rain\", \"snowfall\", \"snow_depth\", \"weather_code\", \"pressure_msl\", \"surface_pressure\", \"cloud_cover\", \"cloud_cover_low\", \"cloud_cover_mid\", \"cloud_cover_high\", \"et0_fao_evapotranspiration\", \"vapour_pressure_deficit\", \"wind_speed_10m\", \"wind_speed_100m\", \"wind_direction_10m\", \"wind_direction_100m\", \"wind_gusts_10m\", \"soil_temperature_0_to_7cm\", \"soil_temperature_7_to_28cm\", \"soil_temperature_28_to_100cm\", \"soil_temperature_100_to_255cm\", \"soil_moisture_0_to_7cm\", \"soil_moisture_7_to_28cm\", \"soil_moisture_28_to_100cm\", \"soil_moisture_100_to_255cm\"]\n",
    "        }\n",
    "        responses = openmeteo.weather_api(url, params=params)\n",
    "\n",
    "        # Process first location. Add a for-loop for multiple locations or weather models\n",
    "        response = responses[0]\n",
    "\n",
    "        # Process hourly data. The order of variables needs to be the same as requested.\n",
    "        hourly = response.Hourly()\n",
    "\n",
    "        # Get data for each var\n",
    "        for i, var_list in enumerate(weather_variables):\n",
    "            var_list.append(hourly.Variables(idx).ValuesAsNumpy()[int(timeStr)])\n",
    "\n",
    "    df_split['temperature_2m'] = temperature_2m_list\n",
    "    df_split['relative_humidity_2m'] = relative_humidity_2m_list\n",
    "    df_split['dew_point_2m'] = dew_point_2m_list\n",
    "    df_split['apparent_temperature'] = apparent_temperature_list\n",
    "    df_split['precipitation'] = precipitation_list\n",
    "    df_split['rain'] = rain_list\n",
    "    df_split['snowfall'] = snowfall_list\n",
    "    df_split['snow_depth'] = snow_depth_list\n",
    "    df_split['weather_code'] = weather_code_list\n",
    "    df_split['pressure_msl'] = pressure_msl_list\n",
    "    df_split['surface_pressure'] = surface_pressure_list\n",
    "    df_split['cloud_cover'] = cloud_cover_list\n",
    "    df_split['cloud_cover_low'] = cloud_cover_low_list\n",
    "    df_split['cloud_cover_mid'] = cloud_cover_mid_list\n",
    "    df_split['cloud_cover_high'] = cloud_cover_high_list\n",
    "    df_split['et0_fao_evapotranspiration'] = et0_fao_evapotranspiration_list\n",
    "    df_split['vapour_pressure_deficit'] = vapour_pressure_deficit_list\n",
    "    df_split['wind_speed_10m'] = wind_speed_10m_list\n",
    "    df_split['wind_speed_100m'] = wind_speed_100m_list\n",
    "    df_split['wind_direction_10m'] = wind_direction_10m_list\n",
    "    df_split['wind_direction_100m'] = wind_direction_100m_list\n",
    "    df_split['wind_gusts_10m'] = wind_gusts_10m_list\n",
    "    df_split['soil_temperature_0_to_7cm'] = soil_temperature_0_to_7cm_list\n",
    "    df_split['soil_temperature_7_to_28cm'] = soil_temperature_7_to_28cm_list\n",
    "    df_split['soil_temperature_28_to_100cm'] = soil_temperature_28_to_100cm_list\n",
    "    df_split['soil_temperature_100_to_255cm'] = soil_temperature_100_to_255cm_list\n",
    "    df_split['soil_moisture_0_to_7cm'] = soil_moisture_0_to_7cm_list\n",
    "    df_split['soil_moisture_7_to_28cm'] = soil_moisture_7_to_28cm_list\n",
    "    df_split['soil_moisture_28_to_100cm'] = soil_moisture_28_to_100cm_list\n",
    "    df_split['soil_moisture_100_to_255cm'] = soil_moisture_100_to_255cm_list\n",
    "    \n",
    "    return df_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'grid_id', 'LAT', 'LON', 'Hour', 'has_tree', 'avg_height',\n",
       "       'avg_diameter', 'avg_year', 'Fraxinus', 'Salix', 'Alnus', 'Quercus',\n",
       "       'Tilia', 'Acer', 'Populus', 'Betula', 'Prunus', 'Platanus', 'Malus',\n",
       "       'Robinia', 'Crataegus', 'Ulmus', 'Carpinus', 'Overig', 'Onbekend'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_samples.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for subplit 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Reimer/opt/anaconda3/envs/fundamentals-data-science/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'row' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m i, df_split \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(df_splits):\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGetting data for subplit \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     splits\u001b[39m.\u001b[39mappend(get_weather_data(df_split))\n\u001b[1;32m      9\u001b[0m negative_samples_with_weather \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(splits, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m, in \u001b[0;36mget_weather_data\u001b[0;34m(df_split)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_weather_data\u001b[39m(df_split):\n\u001b[0;32m----> 3\u001b[0m     latitude \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mLAT\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m     longitude \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mLON\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m     dateStr \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'row' is not defined"
     ]
    }
   ],
   "source": [
    "df_splits = np.array_split(negative_samples, NUM_SPLITS)\n",
    "\n",
    "splits = []\n",
    "for i, df_split in enumerate(df_splits):\n",
    "    print(f\"Getting data for subplit {i}\")\n",
    "    splits.append(get_weather_data(df_split))\n",
    "\n",
    "\n",
    "negative_samples_with_weather = pd.concat(splits, axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fundamentals-data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"tree_data_training\")\n",
    "FEATURE_COLS = ['avg_height', 'avg_year',\n",
    "       'Fraxinus', 'Salix', 'Alnus', 'Quercus', 'Tilia', 'Acer', 'Populus',\n",
    "       'Betula', 'Prunus', 'Platanus', 'Malus', 'Robinia', 'Crataegus',\n",
    "       'Ulmus', 'Carpinus', 'Overig', 'Onbekend', 'temperature_2m', 'relative_humidity_2m', 'dew_point_2m',\n",
    "       'apparent_temperature', 'precipitation', 'rain', 'snowfall',\n",
    "       'snow_depth', 'weather_code', 'pressure_msl', 'surface_pressure',\n",
    "       'wind_speed_10m', 'wind_direction_10m', 'wind_gusts_10m',\n",
    "       'soil_temperature_0_to_7cm', 'soil_temperature_7_to_28cm',\n",
    "       'soil_temperature_28_to_100cm', 'soil_temperature_100_to_255cm',\n",
    "       'soil_moisture_0_to_7cm', 'soil_moisture_7_to_28cm',\n",
    "       'soil_moisture_28_to_100cm', 'soil_moisture_100_to_255cm'\n",
    "       ]\n",
    "\n",
    "TEST_PERCENTAGE = 0.2 # percentage of total\n",
    "VALIDATION_PERCENTAGE = 0.25 # percentage of (1-TEST_PERCENTAGE)*total\n",
    "ID_KEY = \"Incident_ID\"\n",
    "LABEL_KEY = \"Label\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging separate sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in training and testing sets\n",
    "positive_path = DATA_DIR / \"positive_samples.csv\"\n",
    "negative_path = DATA_DIR / \"negative_samples.csv\"\n",
    "positive_samples_df = pd.read_csv(positive_path, sep=\",\", encoding=\"utf-8\")\n",
    "negative_samples_df = pd.read_csv(negative_path, sep=\",\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure both df's have identifiable id\n",
    "# Not really necessary but makes things easier\n",
    "positive_samples_df[ID_KEY] = [\"P\"+str(id_) for id_ in positive_samples_df['Incident_ID']]\n",
    "negative_samples_df[ID_KEY] = [\"N\"+str(id_) for id_ in range(len(negative_samples_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels\n",
    "positive_samples_df[LABEL_KEY] = 1\n",
    "negative_samples_df[LABEL_KEY] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df's\n",
    "pos_columns = positive_samples_df.columns\n",
    "neg_columns = negative_samples_df.columns\n",
    "common_cols = pos_columns.intersection(neg_columns)\n",
    "\n",
    "positive_sub_df = positive_samples_df[common_cols]\n",
    "negative_sub_df = negative_samples_df[common_cols]\n",
    "\n",
    "tree_training_df = pd.concat([positive_sub_df, negative_sub_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN with -1\n",
    "tree_training_df.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Validate - Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tree_training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train - test\n",
    "train_ids, test_ids, train_labels, test_labels = train_test_split(df[ID_KEY], df[LABEL_KEY], test_size=TEST_PERCENTAGE, stratify=df[LABEL_KEY], random_state=42)\n",
    "# train_ids, validation_ids = train_test_split(train_ids, test_size=VALIDATION_PERCENTAGE, stratify=train_labels, random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = df[df[ID_KEY].isin(train_ids)]\n",
    "test_set = df[df[ID_KEY].isin(test_ids)]\n",
    "# validation_set = df[df[ID_KEY].isin(validation_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_set[FEATURE_COLS]\n",
    "y_train = train_set[LABEL_KEY]\n",
    "x_test = test_set[FEATURE_COLS]\n",
    "y_test = test_set[LABEL_KEY]\n",
    "# x_validate = validation_set[FEATURE_COLS]\n",
    "# y_validate = validation_set[LABEL_KEY]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_split=10, random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train, y_train)\n",
    "predictions = clf.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6492829204693611\n"
     ]
    }
   ],
   "source": [
    "rf_f1 = f1_score(y_true=y_test, y_pred=predictions)\n",
    "print(rf_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### grid opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf = RandomForestClassifier(random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': np.arange(20, 100, 20),\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 10, 2],\n",
    "    'min_samples_leaf': np.arange(1, 4, 1),\n",
    "    'max_features': np.arange(0.2, 1.0, 0.2)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='accuracy', cv=3, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[308], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Fit the model to the data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# grid_search.fit(x_train, y_train)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[39m# Get the best parameters and the best model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m best_params \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39;49mbest_params_\n\u001b[1;32m      6\u001b[0m best_model \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_estimator_\n\u001b[1;32m      8\u001b[0m \u001b[39m# Make predictions on the test set using the best model\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "# Fit the model to the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(x_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Best Model Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6388888888888888\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(verbosity=2)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "predictions = clf.predict(x_test)\n",
    "print(f1_score(y_pred=predictions, y_true=y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fundamentals-data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

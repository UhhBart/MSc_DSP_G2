{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"tree_data_training\")\n",
    "TREE_DATA = Path(\"final_data/trees/\")\n",
    "FEATURE_COLS = ['avg_height', 'avg_year', 'has_tree',\n",
    "       'Fraxinus', 'Salix', 'Alnus', 'Quercus', 'Tilia', 'Acer', 'Populus',\n",
    "       'Betula', 'Prunus', 'Platanus', 'Malus', 'Robinia', 'Crataegus',\n",
    "       'Ulmus', 'Carpinus', 'Overig', 'Onbekend', 'temperature_2m', 'relative_humidity_2m', 'dew_point_2m',\n",
    "       'apparent_temperature', 'precipitation', 'rain', 'snowfall',\n",
    "       'snow_depth', 'weather_code', 'pressure_msl', 'surface_pressure',\n",
    "       'wind_speed_10m', 'wind_direction_10m', 'wind_gusts_10m',\n",
    "       'soil_temperature_0_to_7cm', 'soil_temperature_7_to_28cm',\n",
    "       'soil_temperature_28_to_100cm', 'soil_temperature_100_to_255cm',\n",
    "       'soil_moisture_0_to_7cm', 'soil_moisture_7_to_28cm',\n",
    "       'soil_moisture_28_to_100cm', 'soil_moisture_100_to_255cm'\n",
    "       ]\n",
    "\n",
    "\n",
    "\n",
    "TEST_PERCENTAGE = 0.2 # percentage of total\n",
    "VALIDATION_PERCENTAGE = 0.25 # percentage of (1-TEST_PERCENTAGE)*total\n",
    "ID_KEY = \"Incident_ID\"\n",
    "LABEL_KEY = \"Label\"\n",
    "\n",
    "SOIL_MOISTURE_COLUMNS = [\n",
    "    'soil_moisture_0_to_7cm',\n",
    "    'soil_moisture_7_to_28cm', \n",
    "    'soil_moisture_28_to_100cm', \n",
    "    'soil_moisture_100_to_255cm'\n",
    "]\n",
    "\n",
    "SOIL_TEMPERATURE_COLUMNS = [\n",
    "    'soil_temperature_0_to_7cm',\n",
    "    'soil_temperature_7_to_28cm',\n",
    "    'soil_temperature_28_to_100cm',\n",
    "    'soil_temperature_100_to_255cm',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging separate sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in training and testing sets\n",
    "positive_path = TREE_DATA / \"trees_new_grid_pos_samples.csv\"\n",
    "negative_path_t = TREE_DATA / \"trees_new_grid_neg_samples_true.csv\"\n",
    "negative_path_f = TREE_DATA / \"trees_new_grid_neg_samples_false.csv\" \n",
    "\n",
    "positive_samples_df = pd.read_csv(positive_path, sep=\",\", encoding=\"utf-8\")\n",
    "negative_samples_df_t = pd.read_csv(negative_path_t, sep=\",\", encoding=\"utf-8\")\n",
    "negative_samples_df_f = pd.read_csv(negative_path_f, sep=\",\", encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_samples_df = pd.concat([negative_samples_df_t, negative_samples_df_f], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Date</th>\n",
       "      <th>grid_id</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Hour</th>\n",
       "      <th>has_tree</th>\n",
       "      <th>avg_height</th>\n",
       "      <th>avg_diameter</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_direction_100m</th>\n",
       "      <th>wind_gusts_10m</th>\n",
       "      <th>soil_temperature_0_to_7cm</th>\n",
       "      <th>soil_temperature_7_to_28cm</th>\n",
       "      <th>soil_temperature_28_to_100cm</th>\n",
       "      <th>soil_temperature_100_to_255cm</th>\n",
       "      <th>soil_moisture_0_to_7cm</th>\n",
       "      <th>soil_moisture_7_to_28cm</th>\n",
       "      <th>soil_moisture_28_to_100cm</th>\n",
       "      <th>soil_moisture_100_to_255cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-11-15</td>\n",
       "      <td>7798</td>\n",
       "      <td>52.302912</td>\n",
       "      <td>5.009427</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>33.480000</td>\n",
       "      <td>9.287001</td>\n",
       "      <td>8.537001</td>\n",
       "      <td>12.1370</td>\n",
       "      <td>13.637000</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-07-05</td>\n",
       "      <td>1381</td>\n",
       "      <td>52.394804</td>\n",
       "      <td>4.788347</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>268.999330</td>\n",
       "      <td>104.760000</td>\n",
       "      <td>13.237000</td>\n",
       "      <td>16.487000</td>\n",
       "      <td>15.9870</td>\n",
       "      <td>10.787001</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-07-05</td>\n",
       "      <td>7837</td>\n",
       "      <td>52.373183</td>\n",
       "      <td>5.009427</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>234.819210</td>\n",
       "      <td>65.520004</td>\n",
       "      <td>16.693500</td>\n",
       "      <td>17.093500</td>\n",
       "      <td>15.6935</td>\n",
       "      <td>10.943500</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-09-11</td>\n",
       "      <td>5669</td>\n",
       "      <td>52.281291</td>\n",
       "      <td>4.923943</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>143.325560</td>\n",
       "      <td>30.599998</td>\n",
       "      <td>19.850000</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>15.5500</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-07-05</td>\n",
       "      <td>4448</td>\n",
       "      <td>52.310120</td>\n",
       "      <td>4.882675</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>258.074040</td>\n",
       "      <td>103.320000</td>\n",
       "      <td>13.206500</td>\n",
       "      <td>16.656500</td>\n",
       "      <td>16.0065</td>\n",
       "      <td>10.856501</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>1337</td>\n",
       "      <td>2023-09-13</td>\n",
       "      <td>2618</td>\n",
       "      <td>52.369579</td>\n",
       "      <td>4.826668</td>\n",
       "      <td>1950</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22.833694</td>\n",
       "      <td>32.039997</td>\n",
       "      <td>20.130499</td>\n",
       "      <td>19.330500</td>\n",
       "      <td>17.1805</td>\n",
       "      <td>13.280500</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>1338</td>\n",
       "      <td>2022-02-21</td>\n",
       "      <td>7296</td>\n",
       "      <td>52.374985</td>\n",
       "      <td>4.985845</td>\n",
       "      <td>1951</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>288.721040</td>\n",
       "      <td>77.400000</td>\n",
       "      <td>5.780500</td>\n",
       "      <td>6.480500</td>\n",
       "      <td>7.4805</td>\n",
       "      <td>9.830501</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>1339</td>\n",
       "      <td>2022-11-17</td>\n",
       "      <td>6968</td>\n",
       "      <td>52.299309</td>\n",
       "      <td>4.974054</td>\n",
       "      <td>1952</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>130.297870</td>\n",
       "      <td>65.880000</td>\n",
       "      <td>9.243500</td>\n",
       "      <td>9.893499</td>\n",
       "      <td>11.8435</td>\n",
       "      <td>13.543500</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>1340</td>\n",
       "      <td>2022-02-18</td>\n",
       "      <td>4538</td>\n",
       "      <td>52.304714</td>\n",
       "      <td>4.885622</td>\n",
       "      <td>1953</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>249.630600</td>\n",
       "      <td>104.039990</td>\n",
       "      <td>8.419499</td>\n",
       "      <td>8.019500</td>\n",
       "      <td>7.6195</td>\n",
       "      <td>9.919499</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>1341</td>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>6600</td>\n",
       "      <td>52.311921</td>\n",
       "      <td>4.959316</td>\n",
       "      <td>1954</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>200.181870</td>\n",
       "      <td>82.079994</td>\n",
       "      <td>9.824000</td>\n",
       "      <td>11.174000</td>\n",
       "      <td>12.7740</td>\n",
       "      <td>13.974000</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1342 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1        Date  grid_id        LAT       LON  Unnamed: 0  \\\n",
       "0                0  2022-11-15     7798  52.302912  5.009427           0   \n",
       "1                1  2023-07-05     1381  52.394804  4.788347           2   \n",
       "2                2  2020-07-05     7837  52.373183  5.009427           3   \n",
       "3                3  2008-09-11     5669  52.281291  4.923943           6   \n",
       "4                4  2023-07-05     4448  52.310120  4.882675           7   \n",
       "...            ...         ...      ...        ...       ...         ...   \n",
       "1337          1337  2023-09-13     2618  52.369579  4.826668        1950   \n",
       "1338          1338  2022-02-21     7296  52.374985  4.985845        1951   \n",
       "1339          1339  2022-11-17     6968  52.299309  4.974054        1952   \n",
       "1340          1340  2022-02-18     4538  52.304714  4.885622        1953   \n",
       "1341          1341  2023-11-02     6600  52.311921  4.959316        1954   \n",
       "\n",
       "      Hour  has_tree  avg_height  avg_diameter  ...  wind_direction_100m  \\\n",
       "0       10     False         NaN           NaN  ...           180.000000   \n",
       "1        9     False         NaN           NaN  ...           268.999330   \n",
       "2        8     False         NaN           NaN  ...           234.819210   \n",
       "3       10     False         NaN           NaN  ...           143.325560   \n",
       "4        8     False         NaN           NaN  ...           258.074040   \n",
       "...    ...       ...         ...           ...  ...                  ...   \n",
       "1337    15     False         NaN           NaN  ...            22.833694   \n",
       "1338    12     False         NaN           NaN  ...           288.721040   \n",
       "1339     2     False         NaN           NaN  ...           130.297870   \n",
       "1340    17     False         NaN           NaN  ...           249.630600   \n",
       "1341    19     False         NaN           NaN  ...           200.181870   \n",
       "\n",
       "      wind_gusts_10m  soil_temperature_0_to_7cm  soil_temperature_7_to_28cm  \\\n",
       "0          33.480000                   9.287001                    8.537001   \n",
       "1         104.760000                  13.237000                   16.487000   \n",
       "2          65.520004                  16.693500                   17.093500   \n",
       "3          30.599998                  19.850000                   16.750000   \n",
       "4         103.320000                  13.206500                   16.656500   \n",
       "...              ...                        ...                         ...   \n",
       "1337       32.039997                  20.130499                   19.330500   \n",
       "1338       77.400000                   5.780500                    6.480500   \n",
       "1339       65.880000                   9.243500                    9.893499   \n",
       "1340      104.039990                   8.419499                    8.019500   \n",
       "1341       82.079994                   9.824000                   11.174000   \n",
       "\n",
       "      soil_temperature_28_to_100cm  soil_temperature_100_to_255cm  \\\n",
       "0                          12.1370                      13.637000   \n",
       "1                          15.9870                      10.787001   \n",
       "2                          15.6935                      10.943500   \n",
       "3                          15.5500                      13.100000   \n",
       "4                          16.0065                      10.856501   \n",
       "...                            ...                            ...   \n",
       "1337                       17.1805                      13.280500   \n",
       "1338                        7.4805                       9.830501   \n",
       "1339                       11.8435                      13.543500   \n",
       "1340                        7.6195                       9.919499   \n",
       "1341                       12.7740                      13.974000   \n",
       "\n",
       "      soil_moisture_0_to_7cm  soil_moisture_7_to_28cm  \\\n",
       "0                      0.646                    0.621   \n",
       "1                      0.727                    0.509   \n",
       "2                      0.434                    0.358   \n",
       "3                      0.604                    0.599   \n",
       "4                      0.747                    0.456   \n",
       "...                      ...                      ...   \n",
       "1337                   0.603                    0.554   \n",
       "1338                   0.759                    0.744   \n",
       "1339                   0.741                    0.649   \n",
       "1340                   0.727                    0.720   \n",
       "1341                   0.729                    0.727   \n",
       "\n",
       "      soil_moisture_28_to_100cm  soil_moisture_100_to_255cm  \n",
       "0                         0.519                       0.600  \n",
       "1                         0.547                       0.666  \n",
       "2                         0.470                       0.629  \n",
       "3                         0.540                       0.605  \n",
       "4                         0.538                       0.661  \n",
       "...                         ...                         ...  \n",
       "1337                      0.532                       0.635  \n",
       "1338                      0.712                       0.650  \n",
       "1339                      0.558                       0.608  \n",
       "1340                      0.700                       0.679  \n",
       "1341                      0.681                       0.621  \n",
       "\n",
       "[1342 rows x 58 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_samples_df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure both df's have identifiable id\n",
    "# Not really necessary but makes things easier\n",
    "positive_samples_df[ID_KEY] = [\"P\"+str(id_) for id_ in positive_samples_df['Incident_ID']]\n",
    "negative_samples_df[ID_KEY] = [\"N\"+str(id_) for id_ in range(len(negative_samples_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels\n",
    "positive_samples_df[LABEL_KEY] = 1\n",
    "negative_samples_df[LABEL_KEY] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_samples_df = positive_samples_df.fillna(0)\n",
    "negative_samples_df = negative_samples_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df's\n",
    "pos_columns = positive_samples_df.columns\n",
    "neg_columns = negative_samples_df.columns\n",
    "common_cols = pos_columns.intersection(neg_columns)\n",
    "\n",
    "positive_sub_df = positive_samples_df[common_cols]\n",
    "negative_sub_df = negative_samples_df[common_cols]\n",
    "\n",
    "tree_training_df = pd.concat([positive_sub_df, negative_sub_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['grid_id', 'has_tree', 'avg_height', 'avg_diameter', 'avg_year',\n",
       "       'Fraxinus', 'Salix', 'Alnus', 'Quercus', 'Tilia', 'Acer', 'Populus',\n",
       "       'Betula', 'Prunus', 'Platanus', 'Malus', 'Robinia', 'Crataegus',\n",
       "       'Ulmus', 'Carpinus', 'Overig', 'Onbekend', 'Incident_ID',\n",
       "       'Service_Area', 'Date', 'Hour', 'temperature_2m',\n",
       "       'relative_humidity_2m', 'dew_point_2m', 'apparent_temperature',\n",
       "       'precipitation', 'rain', 'snowfall', 'snow_depth', 'weather_code',\n",
       "       'pressure_msl', 'surface_pressure', 'wind_speed_10m',\n",
       "       'wind_direction_10m', 'wind_gusts_10m', 'soil_temperature_0_to_7cm',\n",
       "       'soil_temperature_7_to_28cm', 'soil_temperature_28_to_100cm',\n",
       "       'soil_temperature_100_to_255cm', 'soil_moisture_0_to_7cm',\n",
       "       'soil_moisture_7_to_28cm', 'soil_moisture_28_to_100cm',\n",
       "       'soil_moisture_100_to_255cm', 'Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_samples_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_across_cols(\n",
    "    df,\n",
    "    cols,\n",
    "    new_col\n",
    "):\n",
    "    df[new_col] = df[cols].mean(axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_training_df = average_across_cols(tree_training_df, SOIL_MOISTURE_COLUMNS, \"average_soil_moisture\")\n",
    "tree_training_df = average_across_cols(tree_training_df, SOIL_TEMPERATURE_COLUMNS, \"average_soil_temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tree_training_df.drop(col, axis=1, inplace=True) for col in SOIL_MOISTURE_COLUMNS]\n",
    "[tree_training_df.drop(col, axis=1, inplace=True) for col in SOIL_TEMPERATURE_COLUMNS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Validate - Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tree_training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train - test\n",
    "train_ids, test_ids, train_labels, test_labels = train_test_split(df[ID_KEY], df[LABEL_KEY], test_size=TEST_PERCENTAGE, stratify=df[LABEL_KEY], random_state=42)\n",
    "# train_ids, validation_ids = train_test_split(train_ids, test_size=VALIDATION_PERCENTAGE, stratify=train_labels, random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = df[df[ID_KEY].isin(train_ids)]\n",
    "test_set = df[df[ID_KEY].isin(test_ids)]\n",
    "# validation_set = df[df[ID_KEY].isin(validation_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['avg_height', 'avg_year', 'has_tree', 'Fraxinus', 'Salix', 'Alnus', 'Quercus', 'Tilia', 'Acer', 'Populus', 'Betula', 'Prunus', 'Platanus', 'Malus', 'Robinia', 'Crataegus', 'Ulmus', 'Carpinus', 'Overig', 'Onbekend', 'temperature_2m', 'relative_humidity_2m', 'dew_point_2m', 'apparent_temperature', 'precipitation', 'rain', 'snowfall', 'snow_depth', 'weather_code', 'pressure_msl', 'surface_pressure', 'wind_speed_10m', 'wind_direction_10m', 'wind_gusts_10m']\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [col for col in FEATURE_COLS if col not in SOIL_MOISTURE_COLUMNS and col not in SOIL_TEMPERATURE_COLUMNS]\n",
    "\n",
    "print(feature_cols)\n",
    "\n",
    "x_train = train_set[feature_cols]\n",
    "y_train = train_set[LABEL_KEY]\n",
    "x_test = test_set[feature_cols]\n",
    "y_test = test_set[LABEL_KEY]\n",
    "# x_validate = validation_set[FEATURE_COLS]\n",
    "# y_validate = validation_set[LABEL_KEY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_test(\n",
    "    df,\n",
    "    seed = 42\n",
    "):\n",
    "    train_ids, test_ids, train_labels, test_labels = train_test_split(df[ID_KEY], df[LABEL_KEY], test_size=TEST_PERCENTAGE, stratify=df[LABEL_KEY], random_state=seed)\n",
    "    \n",
    "    feature_cols = [col for col in FEATURE_COLS if col not in SOIL_MOISTURE_COLUMNS and col not in SOIL_TEMPERATURE_COLUMNS]\n",
    "\n",
    "    train_set = df[df[ID_KEY].isin(train_ids)]\n",
    "    test_set = df[df[ID_KEY].isin(test_ids)]\n",
    "\n",
    "    x_train = train_set[feature_cols]\n",
    "    y_train = train_set[LABEL_KEY]\n",
    "    x_test = test_set[feature_cols]\n",
    "    y_test = test_set[LABEL_KEY]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_split=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=20, max_depth=5, min_samples_split=2, min_samples_leaf=8, random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.99      0.82       786\n",
      "           1       0.89      0.12      0.21       393\n",
      "\n",
      "    accuracy                           0.70      1179\n",
      "   macro avg       0.79      0.56      0.51      1179\n",
      "weighted avg       0.76      0.70      0.61      1179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf.fit(x_train, y_train)\n",
    "predictions = clf.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21076233183856502\n"
     ]
    }
   ],
   "source": [
    "rf_f1 = f1_score(y_true=y_test, y_pred=predictions)\n",
    "print(rf_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### grid opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf  = RandomForestClassifier(random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': np.arange(20, 240, 30),\n",
    "    'max_depth': [5, 10, 15, 20, 25],\n",
    "    'min_samples_split': [2, 22, 2],\n",
    "    'min_samples_leaf': np.arange(1, 10, 1),\n",
    "    'max_features': np.arange(0.2, 1.0, 0.2)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='accuracy', cv=3, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4320 candidates, totalling 12960 fits\n",
      "[CV 1/3] END max_depth=5, max_features=0.2, min_samples_leaf=1, min_samples_split=2, n_estimators=20;, score=0.693 total time=   0.1s\n",
      "[CV 2/3] END max_depth=5, max_features=0.2, min_samples_leaf=1, min_samples_split=2, n_estimators=20;, score=0.668 total time=   0.1s\n",
      "[CV 3/3] END max_depth=5, max_features=0.2, min_samples_leaf=1, min_samples_split=2, n_estimators=20;, score=0.703 total time=   0.1s\n",
      "[CV 1/3] END max_depth=5, max_features=0.2, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.689 total time=   0.1s\n",
      "[CV 2/3] END max_depth=5, max_features=0.2, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.667 total time=   0.1s\n",
      "[CV 3/3] END max_depth=5, max_features=0.2, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.702 total time=   0.1s\n",
      "[CV 1/3] END max_depth=5, max_features=0.2, min_samples_leaf=1, min_samples_split=2, n_estimators=80;, score=0.687 total time=   0.1s\n",
      "[CV 2/3] END max_depth=5, max_features=0.2, min_samples_leaf=1, min_samples_split=2, n_estimators=80;, score=0.666 total time=   0.1s\n",
      "[CV 3/3] END max_depth=5, max_features=0.2, min_samples_leaf=1, min_samples_split=2, n_estimators=80;, score=0.702 total time=   0.1s\n",
      "[CV 1/3] END max_depth=5, max_features=0.2, min_samples_leaf=1, min_samples_split=2, n_estimators=110;, score=0.687 total time=   0.2s\n",
      "[CV 2/3] END max_depth=5, max_features=0.2, min_samples_leaf=1, min_samples_split=2, n_estimators=110;, score=0.667 total time=   0.2s\n",
      "[CV 3/3] END max_depth=5, max_features=0.2, min_samples_leaf=1, min_samples_split=2, n_estimators=110;, score=0.701 total time=   0.2s\n",
      "[CV 1/3] END max_depth=5, max_features=0.2, min_samples_leaf=1, min_samples_split=2, n_estimators=140;, score=0.687 total time=   0.2s\n",
      "[CV 2/3] END max_depth=5, max_features=0.2, min_samples_leaf=1, min_samples_split=2, n_estimators=140;, score=0.668 total time=   0.3s\n",
      "[CV 3/3] END max_depth=5, max_features=0.2, min_samples_leaf=1, min_samples_split=2, n_estimators=140;, score=0.703 total time=   0.2s\n",
      "[CV 1/3] END max_depth=5, max_features=0.2, min_samples_leaf=1, min_samples_split=2, n_estimators=170;, score=0.687 total time=   0.3s\n",
      "[CV 2/3] END max_depth=5, max_features=0.2, min_samples_leaf=1, min_samples_split=2, n_estimators=170;, score=0.666 total time=   0.3s\n",
      "[CV 3/3] END max_depth=5, max_features=0.2, min_samples_leaf=1, min_samples_split=2, n_estimators=170;, score=0.703 total time=   0.3s\n",
      "[CV 1/3] END max_depth=5, max_features=0.2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.687 total time=   0.3s\n",
      "[CV 2/3] END max_depth=5, max_features=0.2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.668 total time=   0.3s\n",
      "[CV 3/3] END max_depth=5, max_features=0.2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.702 total time=   0.3s\n",
      "[CV 1/3] END max_depth=5, max_features=0.2, min_samples_leaf=1, min_samples_split=2, n_estimators=230;, score=0.687 total time=   0.4s\n",
      "[CV 2/3] END max_depth=5, max_features=0.2, min_samples_leaf=1, min_samples_split=2, n_estimators=230;, score=0.667 total time=   0.4s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Fit the model to the data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(x_train, y_train)\n\u001b[1;32m      4\u001b[0m \u001b[39m# Get the best parameters and the best model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m best_params \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fundamentals-data-science/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fundamentals-data-science/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fundamentals-data-science/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fundamentals-data-science/lib/python3.11/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fundamentals-data-science/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fundamentals-data-science/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fundamentals-data-science/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fundamentals-data-science/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fundamentals-data-science/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    730\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    731\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 732\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    734\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    735\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fundamentals-data-science/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fundamentals-data-science/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    445\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    447\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    448\u001b[0m ]\n\u001b[1;32m    450\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    457\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    458\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    459\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    460\u001b[0m )(\n\u001b[1;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    462\u001b[0m         t,\n\u001b[1;32m    463\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    464\u001b[0m         X,\n\u001b[1;32m    465\u001b[0m         y,\n\u001b[1;32m    466\u001b[0m         sample_weight,\n\u001b[1;32m    467\u001b[0m         i,\n\u001b[1;32m    468\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    469\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    470\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    471\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    472\u001b[0m     )\n\u001b[1;32m    473\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    474\u001b[0m )\n\u001b[1;32m    476\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fundamentals-data-science/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fundamentals-data-science/lib/python3.11/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fundamentals-data-science/lib/python3.11/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fundamentals-data-science/lib/python3.11/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.01\u001b[39m)\n\u001b[1;32m   1708\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the model to the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(x_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Best Model Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7098445595854922\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(verbosity=2, max_depth=15, subsample=0.9)\n",
    "\n",
    "x_train, y_train, x_test, y_test = make_train_test(df, seed = 42)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "predictions = clf.predict(x_test)\n",
    "print(f1_score(y_pred=predictions, y_true=y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_height : 0.02556045539677143\n",
      "avg_year : 0.10686264932155609\n",
      "has_tree : 0.01237479504197836\n",
      "Fraxinus : 0.02697938308119774\n",
      "Salix : 0.029725905507802963\n",
      "Alnus : 0.027573855593800545\n",
      "Quercus : 0.031595658510923386\n",
      "Tilia : 0.03444623947143555\n",
      "Acer : 0.028514746576547623\n",
      "Populus : 0.03125520050525665\n",
      "Betula : 0.028653353452682495\n",
      "Prunus : 0.031002258881926537\n",
      "Platanus : 0.03469470515847206\n",
      "Malus : 0.04737110808491707\n",
      "Robinia : 0.03827314078807831\n",
      "Crataegus : 0.03139074146747589\n",
      "Ulmus : 0.05017649009823799\n",
      "Carpinus : 0.026593683287501335\n",
      "Overig : 0.036586929112672806\n",
      "Onbekend : 0.04751036688685417\n",
      "temperature_2m : 0.017486436292529106\n",
      "relative_humidity_2m : 0.0191772673279047\n",
      "dew_point_2m : 0.01635928265750408\n",
      "apparent_temperature : 0.01821461319923401\n",
      "precipitation : 0.026385750621557236\n",
      "rain : 0.03108418732881546\n",
      "snowfall : 0.030996670946478844\n",
      "snow_depth : 0.0\n",
      "weather_code : 0.017582161352038383\n",
      "pressure_msl : 0.01956384815275669\n",
      "surface_pressure : 0.01630496233701706\n",
      "wind_speed_10m : 0.020424164831638336\n",
      "wind_direction_10m : 0.019360201433300972\n",
      "wind_gusts_10m : 0.01991880312561989\n"
     ]
    }
   ],
   "source": [
    "for name, score in zip(clf.feature_names_in_, clf.feature_importances_):\n",
    "    print(f\"{name} : {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# #save model\n",
    "# with open(\"models/trees/xgboost_md15_sub90_mixed.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "0.5983827493261457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.78       661\n",
      "           1       0.64      0.56      0.60       393\n",
      "\n",
      "    accuracy                           0.72      1054\n",
      "   macro avg       0.70      0.69      0.69      1054\n",
      "weighted avg       0.71      0.72      0.71      1054\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Reimer/opt/anaconda3/envs/fundamentals-data-science/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/Reimer/opt/anaconda3/envs/fundamentals-data-science/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/Reimer/opt/anaconda3/envs/fundamentals-data-science/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "# Define the f1_score as the scoring metric\n",
    "scorer = make_scorer(f1_score)\n",
    "\n",
    "# Perform 3-fold cross-validation\n",
    "cv_predictions = cross_val_predict(clf, x_train, y_train, cv=3)\n",
    "print(cv_predictions)\n",
    "\n",
    "# Print the mean F1 score across all folds\n",
    "print(f1_score(y_pred=predictions, y_true=y_test))\n",
    "print(classification_report(y_true=y_test, y_pred=predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70       393\n",
      "           1       0.70      0.72      0.71       393\n",
      "\n",
      "    accuracy                           0.70       786\n",
      "   macro avg       0.71      0.70      0.70       786\n",
      "weighted avg       0.71      0.70      0.70       786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[CV 1/3] END ........max_depth=5, subsample=0.1;, score=0.566 total time=   0.5s\n",
      "[CV 2/3] END ........max_depth=5, subsample=0.1;, score=0.568 total time=   0.5s\n",
      "[CV 3/3] END ........max_depth=5, subsample=0.1;, score=0.548 total time=   0.4s\n",
      "[CV 1/3] END ........max_depth=5, subsample=0.3;, score=0.580 total time=   0.5s\n",
      "[CV 2/3] END ........max_depth=5, subsample=0.3;, score=0.555 total time=   0.5s\n",
      "[CV 3/3] END ........max_depth=5, subsample=0.3;, score=0.523 total time=   0.5s\n",
      "[CV 1/3] END ........max_depth=5, subsample=0.5;, score=0.584 total time=   0.5s\n",
      "[CV 2/3] END ........max_depth=5, subsample=0.5;, score=0.560 total time=   0.5s\n",
      "[CV 3/3] END ........max_depth=5, subsample=0.5;, score=0.522 total time=   0.5s\n",
      "[CV 1/3] END ........max_depth=5, subsample=0.7;, score=0.613 total time=   0.5s\n",
      "[CV 2/3] END ........max_depth=5, subsample=0.7;, score=0.530 total time=   0.6s\n",
      "[CV 3/3] END ........max_depth=5, subsample=0.7;, score=0.522 total time=   0.6s\n",
      "[CV 1/3] END ........max_depth=5, subsample=0.9;, score=0.591 total time=   0.6s\n",
      "[CV 2/3] END ........max_depth=5, subsample=0.9;, score=0.573 total time=   0.6s\n",
      "[CV 3/3] END ........max_depth=5, subsample=0.9;, score=0.550 total time=   1.0s\n",
      "[CV 1/3] END .......max_depth=10, subsample=0.1;, score=0.560 total time=   0.8s\n",
      "[CV 2/3] END .......max_depth=10, subsample=0.1;, score=0.510 total time=   0.7s\n",
      "[CV 3/3] END .......max_depth=10, subsample=0.1;, score=0.516 total time=   0.7s\n",
      "[CV 1/3] END .......max_depth=10, subsample=0.3;, score=0.592 total time=   1.0s\n",
      "[CV 2/3] END .......max_depth=10, subsample=0.3;, score=0.548 total time=   0.9s\n",
      "[CV 3/3] END .......max_depth=10, subsample=0.3;, score=0.538 total time=   0.9s\n",
      "[CV 1/3] END .......max_depth=10, subsample=0.5;, score=0.594 total time=   0.9s\n",
      "[CV 2/3] END .......max_depth=10, subsample=0.5;, score=0.557 total time=   1.1s\n",
      "[CV 3/3] END .......max_depth=10, subsample=0.5;, score=0.560 total time=   1.0s\n",
      "[CV 1/3] END .......max_depth=10, subsample=0.7;, score=0.592 total time=   1.4s\n",
      "[CV 2/3] END .......max_depth=10, subsample=0.7;, score=0.554 total time=   1.1s\n",
      "[CV 3/3] END .......max_depth=10, subsample=0.7;, score=0.540 total time=   1.1s\n",
      "[CV 1/3] END .......max_depth=10, subsample=0.9;, score=0.594 total time=   1.1s\n",
      "[CV 2/3] END .......max_depth=10, subsample=0.9;, score=0.539 total time=   1.2s\n",
      "[CV 3/3] END .......max_depth=10, subsample=0.9;, score=0.531 total time=   1.6s\n",
      "[CV 1/3] END .......max_depth=15, subsample=0.1;, score=0.563 total time=   0.8s\n",
      "[CV 2/3] END .......max_depth=15, subsample=0.1;, score=0.497 total time=   1.2s\n",
      "[CV 3/3] END .......max_depth=15, subsample=0.1;, score=0.516 total time=   0.8s\n",
      "[CV 1/3] END .......max_depth=15, subsample=0.3;, score=0.572 total time=   1.2s\n",
      "[CV 2/3] END .......max_depth=15, subsample=0.3;, score=0.534 total time=   0.9s\n",
      "[CV 3/3] END .......max_depth=15, subsample=0.3;, score=0.522 total time=   0.9s\n",
      "[CV 1/3] END .......max_depth=15, subsample=0.5;, score=0.594 total time=   0.9s\n",
      "[CV 2/3] END .......max_depth=15, subsample=0.5;, score=0.548 total time=   1.1s\n",
      "[CV 3/3] END .......max_depth=15, subsample=0.5;, score=0.537 total time=   1.6s\n",
      "[CV 1/3] END .......max_depth=15, subsample=0.7;, score=0.587 total time=   1.3s\n",
      "[CV 2/3] END .......max_depth=15, subsample=0.7;, score=0.523 total time=   1.4s\n",
      "[CV 3/3] END .......max_depth=15, subsample=0.7;, score=0.548 total time=   0.7s\n",
      "[CV 1/3] END .......max_depth=15, subsample=0.9;, score=0.587 total time=   1.3s\n",
      "[CV 2/3] END .......max_depth=15, subsample=0.9;, score=0.574 total time=   1.3s\n",
      "[CV 3/3] END .......max_depth=15, subsample=0.9;, score=0.555 total time=   1.2s\n",
      "[CV 1/3] END .......max_depth=20, subsample=0.1;, score=0.563 total time=   1.0s\n",
      "[CV 2/3] END .......max_depth=20, subsample=0.1;, score=0.497 total time=   1.1s\n",
      "[CV 3/3] END .......max_depth=20, subsample=0.1;, score=0.516 total time=   0.7s\n",
      "[CV 1/3] END .......max_depth=20, subsample=0.3;, score=0.597 total time=   1.0s\n",
      "[CV 2/3] END .......max_depth=20, subsample=0.3;, score=0.534 total time=   0.9s\n",
      "[CV 3/3] END .......max_depth=20, subsample=0.3;, score=0.519 total time=   0.9s\n",
      "[CV 1/3] END .......max_depth=20, subsample=0.5;, score=0.586 total time=   1.1s\n",
      "[CV 2/3] END .......max_depth=20, subsample=0.5;, score=0.537 total time=   1.2s\n",
      "[CV 3/3] END .......max_depth=20, subsample=0.5;, score=0.537 total time=   1.0s\n",
      "[CV 1/3] END .......max_depth=20, subsample=0.7;, score=0.594 total time=   1.1s\n",
      "[CV 2/3] END .......max_depth=20, subsample=0.7;, score=0.551 total time=   1.2s\n",
      "[CV 3/3] END .......max_depth=20, subsample=0.7;, score=0.544 total time=   0.8s\n",
      "[CV 1/3] END .......max_depth=20, subsample=0.9;, score=0.586 total time=   1.3s\n",
      "[CV 2/3] END .......max_depth=20, subsample=0.9;, score=0.562 total time=   1.2s\n",
      "[CV 3/3] END .......max_depth=20, subsample=0.9;, score=0.523 total time=   1.3s\n",
      "[CV 1/3] END .......max_depth=25, subsample=0.1;, score=0.563 total time=   0.8s\n",
      "[CV 2/3] END .......max_depth=25, subsample=0.1;, score=0.497 total time=   0.7s\n",
      "[CV 3/3] END .......max_depth=25, subsample=0.1;, score=0.516 total time=   0.7s\n",
      "[CV 1/3] END .......max_depth=25, subsample=0.3;, score=0.597 total time=   0.9s\n",
      "[CV 2/3] END .......max_depth=25, subsample=0.3;, score=0.534 total time=   0.7s\n",
      "[CV 3/3] END .......max_depth=25, subsample=0.3;, score=0.519 total time=   1.1s\n",
      "[CV 1/3] END .......max_depth=25, subsample=0.5;, score=0.586 total time=   2.1s\n",
      "[CV 2/3] END .......max_depth=25, subsample=0.5;, score=0.537 total time=   1.2s\n",
      "[CV 3/3] END .......max_depth=25, subsample=0.5;, score=0.537 total time=   1.1s\n",
      "[CV 1/3] END .......max_depth=25, subsample=0.7;, score=0.591 total time=   1.6s\n",
      "[CV 2/3] END .......max_depth=25, subsample=0.7;, score=0.560 total time=   1.4s\n",
      "[CV 3/3] END .......max_depth=25, subsample=0.7;, score=0.544 total time=   1.2s\n",
      "[CV 1/3] END .......max_depth=25, subsample=0.9;, score=0.587 total time=   1.5s\n",
      "[CV 2/3] END .......max_depth=25, subsample=0.9;, score=0.576 total time=   1.3s\n",
      "[CV 3/3] END .......max_depth=25, subsample=0.9;, score=0.546 total time=   1.1s\n",
      "[CV 1/3] END .....max_depth=None, subsample=0.1;, score=0.542 total time=   0.7s\n",
      "[CV 2/3] END .....max_depth=None, subsample=0.1;, score=0.516 total time=   0.7s\n",
      "[CV 3/3] END .....max_depth=None, subsample=0.1;, score=0.532 total time=   0.8s\n",
      "[CV 1/3] END .....max_depth=None, subsample=0.3;, score=0.592 total time=   0.6s\n",
      "[CV 2/3] END .....max_depth=None, subsample=0.3;, score=0.547 total time=   0.7s\n",
      "[CV 3/3] END .....max_depth=None, subsample=0.3;, score=0.507 total time=   0.7s\n",
      "[CV 1/3] END .....max_depth=None, subsample=0.5;, score=0.584 total time=   0.8s\n",
      "[CV 2/3] END .....max_depth=None, subsample=0.5;, score=0.535 total time=   0.6s\n",
      "[CV 3/3] END .....max_depth=None, subsample=0.5;, score=0.535 total time=   0.6s\n",
      "[CV 1/3] END .....max_depth=None, subsample=0.7;, score=0.583 total time=   0.6s\n",
      "[CV 2/3] END .....max_depth=None, subsample=0.7;, score=0.548 total time=   0.6s\n",
      "[CV 3/3] END .....max_depth=None, subsample=0.7;, score=0.537 total time=   0.6s\n",
      "[CV 1/3] END .....max_depth=None, subsample=0.9;, score=0.610 total time=   0.6s\n",
      "[CV 2/3] END .....max_depth=None, subsample=0.9;, score=0.556 total time=   0.5s\n",
      "[CV 3/3] END .....max_depth=None, subsample=0.9;, score=0.540 total time=   0.6s\n",
      "Best Parameters: {'max_depth': 15, 'subsample': 0.9}\n",
      "Best Model Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, 15, 20, 25, None],\n",
    "    'subsample': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='accuracy', cv=3, verbose=3)\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(x_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Best Model Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5983827493261457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Reimer/opt/anaconda3/envs/fundamentals-data-science/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "\n",
    "x_train, y_train, x_test, y_test = make_train_test(df, seed = 42)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "predictions = clf.predict(x_test)\n",
    "print(f1_score(y_pred=predictions, y_true=y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fundamentals-data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

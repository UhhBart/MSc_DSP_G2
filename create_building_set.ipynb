{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from geopy.geocoders import Nominatim\n",
    "from tqdm import tqdm\n",
    "from geopy.distance import geodesic\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import math\n",
    "import datetime\n",
    "import geopandas as gpd\n",
    "import urllib.request\n",
    "import requests\n",
    "import json\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "from shapely.geometry import Polygon, Point\n",
    "from retry_requests import retry\n",
    "from shapely.wkt import loads\n",
    "import random \n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_BOMEN = Path(\"src/data_bomen\")\n",
    "DATA_DIR_GEBOUWEN = Path(\"src/data_gebouwen\")\n",
    "\n",
    "INCIDENT_DATA_PATH = DATA_DIR_BOMEN / 'Incidenten_oorspronkelijk_volledig.csv'\n",
    "BOUWJAAR_DATA_PATH = DATA_DIR_GEBOUWEN / 'BOUWJAAR.csv'\n",
    "ZIPCODE_JSON_PATH = DATA_DIR_BOMEN / \"zipcodes_boxes.json\"\n",
    "GRID_SIZE = 200     ## GRID SIZE IN METERS\n",
    "\n",
    "BUILDING_DATA_CLEAN_PATH = DATA_DIR_GEBOUWEN / f\"building_geo_data_clean_{str(GRID_SIZE)}.csv\"\n",
    "GRID_DATA_PATH = DATA_DIR_GEBOUWEN / f\"grid_enriched_buildings_{GRID_SIZE}.csv\"\n",
    "INCIDENTS_WEATHER_PATH = DATA_DIR_GEBOUWEN / \"Building_incident_with_weather_data.csv\"\n",
    "INCIDENTS_WEATHER_GEO_PATH = DATA_DIR_GEBOUWEN / f\"incidents_weather_geo_buildings_{GRID_SIZE}.csv\"\n",
    "\n",
    "POSITIVE_SAMPLES_PATH = DATA_DIR_GEBOUWEN / f\"positive_samples_buildings_{GRID_SIZE}.csv\"\n",
    "NEGATIVE_SAMPLES_PATH = DATA_DIR_GEBOUWEN / f\"negative_samples_buildings_{GRID_SIZE}.csv\"\n",
    "\n",
    "ZIP_KEY = \"Zipcode\"\n",
    "ZIP4_KEY = \"Zip4\"\n",
    "\n",
    "DATE_WINDOW = 5\n",
    "\n",
    "AMSTERDAM_BBOX = (52.26618, 4.64663, 52.475115999999994, 5.150491999999999)\n",
    "\n",
    "# GRID PATH 200 by 200\n",
    "GRIDS_200_AMSTERDAM_PATH = Path(\"src/final_data/grids/grids_200_amsterdam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUILDING_COLUMNS = [\n",
    "    \"OBJECTNUMMER\",\n",
    "    \"grid_id\",\n",
    "    \"Bouwjaar\",       \n",
    "    \"WKT_LNG_LAT\",\n",
    "    \"WKT_LAT_LNG\",\n",
    "    \"LNG\",\n",
    "    \"LAT\"\n",
    "]\n",
    "\n",
    "SERVICE_AREAS_OUT_OF_SCOPE = [\n",
    "    \"Amstelveen\",\n",
    "    \"Aalsmeer\",\n",
    "    \"Uithoorn\"\n",
    "]\n",
    "\n",
    "INCIDENT_COLUMNS = [\n",
    "    \"Incident_ID\",\n",
    "    \"Service_Area\",\n",
    "    \"grid_id\",\n",
    "    \"Date\",\n",
    "    \"Hour\",\n",
    "    \"temperature_2m\",\n",
    "    \"relative_humidity_2m\",\n",
    "    \"dew_point_2m\",\n",
    "    \"apparent_temperature\",\n",
    "    \"precipitation\",\n",
    "    \"rain\",\n",
    "    \"snowfall\",\n",
    "    \"snow_depth\",\n",
    "    \"weather_code\",\n",
    "    \"pressure_msl\",\n",
    "    \"surface_pressure\",\n",
    "    \"wind_speed_10m\",\n",
    "    \"wind_direction_10m\",\n",
    "    \"wind_gusts_10m\",\n",
    "    \"soil_temperature_0_to_7cm\",\n",
    "    \"soil_temperature_7_to_28cm\",\n",
    "    \"soil_temperature_28_to_100cm\",\n",
    "    \"soil_temperature_100_to_255cm\",\n",
    "    \"soil_moisture_0_to_7cm\",\n",
    "    \"soil_moisture_7_to_28cm\",\n",
    "    \"soil_moisture_28_to_100cm\",\n",
    "    \"soil_moisture_100_to_255cm\",\n",
    "]\n",
    "\n",
    "GRID_COLUMNS = [\n",
    "    \"grid_id\",\n",
    "    \"has_building\",\n",
    "    \"Gemiddelde Bouwjaar\",\n",
    "    \"Voor 1860\",\n",
    "    \"1860-1919\",\n",
    "    \"1920-1939\",\n",
    "    \"1940-1969\",\n",
    "    \"1970-1985\",\n",
    "    \"1986-2001\",\n",
    "    \"Na 2001\"\n",
    "]\n",
    "\n",
    "BUILDING_COLUMNS_MODEL = [\n",
    "    \"building_id\",\n",
    "    \"Bouwjaar\",       \n",
    "    \"WKT_LNG_LAT\",\n",
    "    \"WKT_LAT_LNG\",\n",
    "    \"LNG\",\n",
    "    \"LAT\",\n",
    "    \"bouwjaar_category\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_grid_gdf():\n",
    "#     geolocator = Nominatim(user_agent=\"user_agent\")\n",
    "\n",
    "#     # Get coordinates for Amsterdam\n",
    "#     location = geolocator.geocode(\"Amsterdam, Netherlands\")\n",
    "#     # amsterdam_lat, amsterdam_lon = location.latitude, location.longitude\n",
    "#     amsterdam_lat, amsterdam_lon = [4.88, 52.32]\n",
    "\n",
    "#     amsterdam_bbox = AMSTERDAM_BBOX\n",
    "\n",
    "#     # Calculate grid bounds\n",
    "#     lat_step = GRID_SIZE / 111000  # 1 degree of latitude is approximately 111 kilometers\n",
    "#     lon_step = (GRID_SIZE / 111000) / np.cos(np.radians(amsterdam_lat))  # Correct for latitude\n",
    "\n",
    "#     grid_polygons = []\n",
    "#     for lat in np.arange(amsterdam_bbox[0], amsterdam_bbox[2], lat_step):\n",
    "#         for lon in np.arange(amsterdam_bbox[1], amsterdam_bbox[3], lon_step):\n",
    "#             polygon = Polygon([\n",
    "#                 (lon, lat),\n",
    "#                 (lon + lon_step, lat),\n",
    "#                 (lon + lon_step, lat + lat_step),\n",
    "#                 (lon, lat + lat_step),\n",
    "#                 (lon, lat),\n",
    "#             ])\n",
    "#             grid_polygons.append(polygon)\n",
    "\n",
    "#     grid_gdf = gpd.GeoDataFrame(geometry=grid_polygons, crs=\"EPSG:4326\")\n",
    "#     return grid_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_building_incident_gdf(incidents_weather_df, buildings, grid_gdf):\n",
    "#     # Filter on areas in scope\n",
    "#     incidents_weather_df = incidents_weather_df[~incidents_weather_df.Service_Area.isin(SERVICE_AREAS_OUT_OF_SCOPE)]\n",
    "\n",
    "#     # create gdf from buildings\n",
    "#     building_gdf = gpd.GeoDataFrame(buildings, geometry=gpd.points_from_xy(buildings['LNG'], buildings['LAT']), crs=\"EPSG:4326\")\n",
    "#     # create gdf from indicents\n",
    "#     incident_gdf = gpd.GeoDataFrame(incidents_weather_df, geometry=gpd.points_from_xy(incidents_weather_df['LON'], incidents_weather_df['LAT']), crs=\"EPSG:4326\")\n",
    "#     #join with grid gdf\n",
    "#     building_gdf = gpd.sjoin(building_gdf, grid_gdf, how=\"left\", op=\"within\")\n",
    "#     incident_gdf = gpd.sjoin(incident_gdf, grid_gdf, how=\"left\", op=\"within\")\n",
    "\n",
    "#     #clean up gdf\n",
    "#     building_gdf = building_gdf.rename(columns={\"index_right\" : \"grid_id\", \"geometry\" : \"location\"})\n",
    "#     incident_gdf = incident_gdf.rename(columns={\"index_right\" : \"grid_id\", \"geometry\" : \"location\"})\n",
    "\n",
    "#     return building_gdf, incident_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aliha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:3466: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n",
      "C:\\Users\\Aliha\\AppData\\Local\\Temp\\ipykernel_19776\\3612614206.py:27: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: EPSG:4326\n",
      "Right CRS: None\n",
      "\n",
      "  buildings_geo = gpd.sjoin(buildings_geo, grids, how=\"left\", op=\"within\")\n",
      "C:\\Users\\Aliha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:3466: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n",
      "C:\\Users\\Aliha\\AppData\\Local\\Temp\\ipykernel_19776\\3612614206.py:28: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: EPSG:4326\n",
      "Right CRS: None\n",
      "\n",
      "  incidents_geo = gpd.sjoin(incidents_geo, grids, how=\"left\", op=\"within\")\n",
      "C:\\Users\\Aliha\\AppData\\Local\\Temp\\ipykernel_19776\\3612614206.py:65: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'False' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  grids.at[i, \"has_building\"] = False\n",
      "C:\\Users\\Aliha\\AppData\\Local\\Temp\\ipykernel_19776\\3612614206.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  negatives[GRID_COLUMNS] = None\n",
      "C:\\Users\\Aliha\\AppData\\Local\\Temp\\ipykernel_19776\\3612614206.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  negatives[GRID_COLUMNS] = None\n",
      "C:\\Users\\Aliha\\AppData\\Local\\Temp\\ipykernel_19776\\3612614206.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  negatives[GRID_COLUMNS] = None\n",
      "C:\\Users\\Aliha\\AppData\\Local\\Temp\\ipykernel_19776\\3612614206.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  negatives[GRID_COLUMNS] = None\n",
      "C:\\Users\\Aliha\\AppData\\Local\\Temp\\ipykernel_19776\\3612614206.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  negatives[GRID_COLUMNS] = None\n",
      "C:\\Users\\Aliha\\AppData\\Local\\Temp\\ipykernel_19776\\3612614206.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  negatives[GRID_COLUMNS] = None\n",
      "C:\\Users\\Aliha\\AppData\\Local\\Temp\\ipykernel_19776\\3612614206.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  negatives[GRID_COLUMNS] = None\n",
      "C:\\Users\\Aliha\\AppData\\Local\\Temp\\ipykernel_19776\\3612614206.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  negatives[GRID_COLUMNS] = None\n",
      "C:\\Users\\Aliha\\AppData\\Local\\Temp\\ipykernel_19776\\3612614206.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  negatives[GRID_COLUMNS] = None\n",
      "C:\\Users\\Aliha\\AppData\\Local\\Temp\\ipykernel_19776\\3612614206.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  negatives[GRID_COLUMNS] = None\n"
     ]
    }
   ],
   "source": [
    "# GRIDS\n",
    "grids = pd.read_csv(GRIDS_200_AMSTERDAM_PATH, sep=\";\", encoding=\"utf-8\")\n",
    "grids = gpd.GeoDataFrame(grids, geometry=gpd.GeoSeries.from_wkt(grids['geometry']))\n",
    "\n",
    "# INCIDENTS\n",
    "incidents = pd.read_csv(INCIDENT_DATA_PATH, sep=\",\", encoding=\"utf-8\")\n",
    "incidents = incidents.set_index('Incident_ID')\n",
    "\n",
    "# BUILDINGS\n",
    "buildings = pd.read_csv(BOUWJAAR_DATA_PATH, sep=\";\", encoding=\"utf-8\")\n",
    "buildings['WKT_LNG_LAT'] = buildings['WKT_LNG_LAT'].apply(loads)\n",
    "buildings['WKT_LAT_LNG'] = buildings['WKT_LAT_LNG'].apply(loads)\n",
    "\n",
    "# BUILDING INCIDENTS WITH WEATHER DATA\n",
    "building_incidents_weather = pd.read_csv(INCIDENTS_WEATHER_PATH, sep=\",\", encoding=\"utf-8\")\n",
    "building_incidents_weather = building_incidents_weather[~building_incidents_weather.Service_Area.isin(SERVICE_AREAS_OUT_OF_SCOPE)]\n",
    "\n",
    "# BUILDING INCIDENTS WITHOUT WEATHER DATA\n",
    "building_incidents = incidents[incidents[\"Damage_Type\"]==\"Building\"]\n",
    "building_incidents = building_incidents[~building_incidents.Service_Area.isin(SERVICE_AREAS_OUT_OF_SCOPE)]\n",
    "\n",
    "# GEODATAFRAME BUILDINGS\n",
    "buildings_geo = gpd.GeoDataFrame(buildings, geometry=gpd.points_from_xy(buildings['LNG'], buildings['LAT']), crs=\"EPSG:4326\")\n",
    "incidents_geo = gpd.GeoDataFrame(building_incidents_weather, geometry=gpd.points_from_xy(building_incidents_weather['LON'], building_incidents_weather['LAT']), crs=\"EPSG:4326\")\n",
    "\n",
    "# MAP BUILDINGS AND INCIDENTS TO GRID IDS\n",
    "buildings_geo = gpd.sjoin(buildings_geo, grids, how=\"left\", op=\"within\")\n",
    "incidents_geo = gpd.sjoin(incidents_geo, grids, how=\"left\", op=\"within\")\n",
    "\n",
    "buildings_geo = buildings_geo.rename(columns={\"index_right\" : \"grid_id\", \"geometry\" : \"location\"})\n",
    "incidents_geo = incidents_geo.rename(columns={\"index_right\" : \"grid_id\", \"geometry\" : \"location\"})\n",
    "\n",
    "# GET RID OF UNNECESSARY COLUMNS\n",
    "buildings_geo = buildings_geo[BUILDING_COLUMNS]\n",
    "\n",
    "def map_bouwjaar_to_category(bouwjaar):\n",
    "    if bouwjaar < 1860:\n",
    "        return \"Voor 1860\"\n",
    "    elif 1860 <= bouwjaar <= 1919:\n",
    "        return \"1860-1919\"\n",
    "    elif 1920 <= bouwjaar <= 1939:\n",
    "        return \"1920-1939\"\n",
    "    elif 1940 <= bouwjaar <= 1969:\n",
    "        return \"1940-1969\"\n",
    "    elif 1970 <= bouwjaar <= 1985:\n",
    "        return \"1970-1985\"\n",
    "    elif 1986 <= bouwjaar <= 2001:\n",
    "        return \"1986-2001\"\n",
    "    else:\n",
    "        return \"Na 2001\"\n",
    "\n",
    "# BOUWJAAR CATEGORIE MAKEN\n",
    "buildings_geo['bouwjaar_category'] = buildings_geo['Bouwjaar'].apply(map_bouwjaar_to_category)\n",
    "\n",
    "\n",
    "# ENRICH \n",
    "for i in grids.index:\n",
    "    buildings_geo_sub = buildings_geo[buildings_geo.grid_id == i]\n",
    "    if len(buildings_geo_sub) > 0:\n",
    "        grids.at[i, \"Gemiddelde Bouwjaar\"] = round(np.mean(buildings_geo_sub.Bouwjaar.values), 3)\n",
    "        for name, count in buildings_geo_sub.bouwjaar_category.value_counts().items():\n",
    "            grids.at[i, \"has_building\"] = True\n",
    "            grids.at[i, name] = count\n",
    "    else:\n",
    "        grids.at[i, \"has_building\"] = False\n",
    "grids.fillna(0, inplace=True)\n",
    "\n",
    "# SAVE BUILDING AND INCIDENT DATA \n",
    "buildings_geo.to_csv(BUILDING_DATA_CLEAN_PATH, sep=\",\", encoding=\"utf-8\", index=False)\n",
    "incidents_geo.to_csv(INCIDENTS_WEATHER_GEO_PATH, sep=\",\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "# CLEAN AND SAVE GRID DATA\n",
    "grids = grids.fillna(0)\n",
    "grids[grids.has_building == True]\n",
    "grids['grid_id'] = grids.index\n",
    "grids.to_csv(GRID_DATA_PATH, sep=\",\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "# CREATE AND SAVE POSITIVE SAMPLES\n",
    "incidents_geo.Date = pd.to_datetime(incidents_geo.Date)\n",
    "incidents_geo_positive = incidents_geo[INCIDENT_COLUMNS]\n",
    "\n",
    "grids['grid_id'] = grids.index\n",
    "grids_positive = grids[GRID_COLUMNS]\n",
    "\n",
    "buildings_geo = buildings_geo.rename(columns={\"OBJECTNUMMER\" : \"building_id\"})\n",
    "buildings_geo_positive = buildings_geo[BUILDING_COLUMNS_MODEL]\n",
    "\n",
    "positive_samples = grids_positive.merge(incidents_geo_positive, on='grid_id', how='inner')\n",
    "positive_samples.to_csv(POSITIVE_SAMPLES_PATH, sep=\",\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "# CREATE AND SAVE NEGATIVE SAMPLES WITHOUT WEATHER DATA\n",
    "def verify_sample(incidents, grid_id, date, window=DATE_WINDOW):\n",
    "    start_date = date - pd.DateOffset(days=window)\n",
    "    end_date = date + pd.DateOffset(days=window)\n",
    "\n",
    "    incidents['Date'] = pd.to_datetime(incidents['Date'])  # Convert 'Date' column to Timestamp\n",
    "\n",
    "    grids = incidents[(incidents['Date'] >= start_date) & (incidents['Date'] <= end_date)].values\n",
    "    return False if grid_id not in grids else True\n",
    "\n",
    "grids_with_building = list(grids[grids.has_building == True].grid_id.values)\n",
    "negatives = positive_samples[['Date', 'Hour']]\n",
    "negatives[GRID_COLUMNS] = None\n",
    "\n",
    "for i, row in negatives.iterrows():\n",
    "    random_grid = random.sample(grids_with_building, 1)[0]\n",
    "    while(verify_sample(incidents, random_grid, row.Date)):\n",
    "        random_grid = random.sample(grids_with_building, 1)[0]\n",
    "    grid_data = grids[grids.grid_id == random_grid][GRID_COLUMNS].reset_index(drop=True)\n",
    "    negatives.loc[i, GRID_COLUMNS] = grid_data.iloc[0]\n",
    "\n",
    "negatives.to_csv(NEGATIVE_SAMPLES_PATH, sep=\",\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRIDS\n",
    "grids = pd.read_csv(GRIDS_200_AMSTERDAM_PATH, sep=\";\", encoding=\"utf-8\")\n",
    "grids = gpd.GeoDataFrame(grids, geometry=gpd.GeoSeries.from_wkt(grids['geometry']))\n",
    "\n",
    "# INCIDENTS\n",
    "incidents = pd.read_csv(INCIDENT_DATA_PATH, sep=\",\", encoding=\"utf-8\")\n",
    "incidents = incidents.set_index('Incident_ID')\n",
    "\n",
    "# BUILDINGS\n",
    "buildings = pd.read_csv(BOUWJAAR_DATA_PATH, sep=\";\", encoding=\"utf-8\")\n",
    "buildings['WKT_LNG_LAT'] = buildings['WKT_LNG_LAT'].apply(loads)\n",
    "buildings['WKT_LAT_LNG'] = buildings['WKT_LAT_LNG'].apply(loads)\n",
    "\n",
    "# BUILDING INCIDENTS WITH WEATHER DATA\n",
    "building_incidents_weather = pd.read_csv(INCIDENTS_WEATHER_PATH, sep=\",\", encoding=\"utf-8\")\n",
    "building_incidents_weather = building_incidents_weather[~building_incidents_weather.Service_Area.isin(SERVICE_AREAS_OUT_OF_SCOPE)]\n",
    "\n",
    "# BUILDING INCIDENTS WITHOUT WEATHER DATA\n",
    "building_incidents = incidents[incidents[\"Damage_Type\"]==\"Building\"]\n",
    "building_incidents = building_incidents[~building_incidents.Service_Area.isin(SERVICE_AREAS_OUT_OF_SCOPE)]\n",
    "\n",
    "# GEODATAFRAME BUILDINGS\n",
    "buildings_geo = gpd.GeoDataFrame(buildings, geometry=gpd.points_from_xy(buildings['LNG'], buildings['LAT']), crs=\"EPSG:4326\")\n",
    "incidents_geo = gpd.GeoDataFrame(building_incidents_weather, geometry=gpd.points_from_xy(building_incidents_weather['LON'], building_incidents_weather['LAT']), crs=\"EPSG:4326\")\n",
    "\n",
    "# MAP BUILDINGS AND INCIDENTS TO GRID IDS\n",
    "buildings_geo = gpd.sjoin(buildings_geo, grids, how=\"left\", op=\"within\")\n",
    "incidents_geo = gpd.sjoin(incidents_geo, grids, how=\"left\", op=\"within\")\n",
    "\n",
    "buildings_geo = buildings_geo.rename(columns={\"index_right\" : \"grid_id\", \"geometry\" : \"location\"})\n",
    "incidents_geo = incidents_geo.rename(columns={\"index_right\" : \"grid_id\", \"geometry\" : \"location\"})\n",
    "\n",
    "# GET RID OF UNNECESSARY COLUMNS\n",
    "buildings_geo = buildings_geo[BUILDING_COLUMNS]\n",
    "\n",
    "def map_bouwjaar_to_category(bouwjaar):\n",
    "    if bouwjaar < 1860:\n",
    "        return \"Voor 1860\"\n",
    "    elif 1860 <= bouwjaar <= 1919:\n",
    "        return \"1860-1919\"\n",
    "    elif 1920 <= bouwjaar <= 1939:\n",
    "        return \"1920-1939\"\n",
    "    elif 1940 <= bouwjaar <= 1969:\n",
    "        return \"1940-1969\"\n",
    "    elif 1970 <= bouwjaar <= 1985:\n",
    "        return \"1970-1985\"\n",
    "    elif 1986 <= bouwjaar <= 2001:\n",
    "        return \"1986-2001\"\n",
    "    else:\n",
    "        return \"Na 2001\"\n",
    "\n",
    "# BOUWJAAR CATEGORIE MAKEN\n",
    "buildings_geo['bouwjaar_category'] = buildings_geo['Bouwjaar'].apply(map_bouwjaar_to_category)\n",
    "\n",
    "\n",
    "# ENRICH \n",
    "for i in grids.index:\n",
    "    buildings_geo_sub = buildings_geo[buildings_geo.grid_id == i]\n",
    "    if len(buildings_geo_sub) > 0:\n",
    "        grids.at[i, \"Gemiddelde Bouwjaar\"] = round(np.mean(buildings_geo_sub.Bouwjaar.values), 3)\n",
    "        for name, count in buildings_geo_sub.bouwjaar_category.value_counts().items():\n",
    "            grids.at[i, \"has_building\"] = True\n",
    "            grids.at[i, name] = count\n",
    "    else:\n",
    "        grids.at[i, \"has_building\"] = False\n",
    "grids.fillna(0, inplace=True)\n",
    "\n",
    "# SAVE BUILDING AND INCIDENT DATA \n",
    "buildings_geo.to_csv(BUILDING_DATA_CLEAN_PATH, sep=\",\", encoding=\"utf-8\", index=False)\n",
    "incidents_geo.to_csv(INCIDENTS_WEATHER_GEO_PATH, sep=\",\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "# CLEAN AND SAVE GRID DATA\n",
    "grids = grids.fillna(0)\n",
    "grids[grids.has_building == True]\n",
    "grids['grid_id'] = grids.index\n",
    "grids.to_csv(GRID_DATA_PATH, sep=\",\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "# CREATE AND SAVE POSITIVE SAMPLES\n",
    "incidents_geo.Date = pd.to_datetime(incidents_geo.Date)\n",
    "incidents_geo_positive = incidents_geo[INCIDENT_COLUMNS]\n",
    "\n",
    "grids['grid_id'] = grids.index\n",
    "grids_positive = grids[GRID_COLUMNS]\n",
    "\n",
    "buildings_geo = buildings_geo.rename(columns={\"OBJECTNUMMER\" : \"building_id\"})\n",
    "buildings_geo_positive = buildings_geo[BUILDING_COLUMNS_MODEL]\n",
    "\n",
    "positive_samples = grids_positive.merge(incidents_geo_positive, on='grid_id', how='inner')\n",
    "positive_samples.to_csv(POSITIVE_SAMPLES_PATH, sep=\",\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "# CREATE AND SAVE NEGATIVE SAMPLES WITHOUT WEATHER DATA\n",
    "def verify_sample(incidents, grid_id, date, window=DATE_WINDOW):\n",
    "    start_date = date - pd.DateOffset(days=window)\n",
    "    end_date = date + pd.DateOffset(days=window)\n",
    "\n",
    "    incidents['Date'] = pd.to_datetime(incidents['Date'])  # Convert 'Date' column to Timestamp\n",
    "\n",
    "    grids = incidents[(incidents['Date'] >= start_date) & (incidents['Date'] <= end_date)].values\n",
    "    return False if grid_id not in grids else True\n",
    "\n",
    "grids_with_building = list(grids[grids.has_building == True].grid_id.values)\n",
    "negatives = positive_samples[['Date', 'Hour']]\n",
    "negatives[GRID_COLUMNS] = None\n",
    "\n",
    "for i, row in negatives.iterrows():\n",
    "    random_grid = random.sample(grids_with_building, 1)[0]\n",
    "    while(verify_sample(incidents, random_grid, row.Date)):\n",
    "        random_grid = random.sample(grids_with_building, 1)[0]\n",
    "    grid_data = grids[grids.grid_id == random_grid][GRID_COLUMNS].reset_index(drop=True)\n",
    "    negatives.loc[i, GRID_COLUMNS] = grid_data.iloc[0]\n",
    "\n",
    "negatives.to_csv(NEGATIVE_SAMPLES_PATH, sep=\",\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_cat_to_avg(\n",
    "#     cat_values,\n",
    "#     delimeter = \"-\"\n",
    "# ):\n",
    "#     ''' \n",
    "#     Converts categorical values to means of type float\n",
    "#     Splits cat values on delimter, computes the mean for each cat\n",
    "#     Returns mean of all means of the categories\n",
    "#     '''\n",
    "#     means = []\n",
    "#     for cat in cat_values:\n",
    "#         if not isinstance(cat, str):\n",
    "#             continue\n",
    "#         if not delimeter in cat:\n",
    "#             continue\n",
    "#         vals = cat.split(delimeter)\n",
    "#         means.append(np.mean([float(val) for val in vals]))\n",
    "#     m = round(np.mean(means), 3)\n",
    "#     return 0 if np.isnan(m) else m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def enrich_grid_df(\n",
    "#     grid_gdf,\n",
    "#     building_gdf\n",
    "# ):\n",
    "#     for i in grid_gdf.index:\n",
    "#         building_sub_df = building_gdf[building_gdf.grid_id == i]\n",
    "#         if len(building_sub_df)>0:\n",
    "#             # Compute and add averages for height, diameter and year\n",
    "#             grid_gdf.at[i, \"Bouwjaar\"] = round(np.mean(building_sub_df.Bouwjaar.values), 3)\n",
    "#             # Add soortnaam counts\n",
    "#             # for name, count in building_sub_df.soortnaamKort.value_counts().items():\n",
    "#             #     grid_gdf.at[i, \"has_building\"] = True\n",
    "#             #     grid_gdf.at[i, name] = count\n",
    "#         else:\n",
    "#             grid_gdf.at[i, \"has_building\"] = False\n",
    "\n",
    "#     return grid_gdf, building_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_data(building_gdf, incident_gdf, grid_gdf):\n",
    "#     # save data\n",
    "#     building_gdf.to_csv(BUILDING_DATA_CLEAN_PATH, sep=\",\", encoding=\"utf-8\", index=False)\n",
    "#     incident_gdf.to_csv(INCIDENTS_WEATHER_GEO_PATH, sep=\",\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "#     # clean and save data\n",
    "#     grid_gdf = grid_gdf.fillna(0)\n",
    "#     grid_gdf[grid_gdf.has_building == True]\n",
    "#     grid_gdf['grid_id'] = grid_gdf.index\n",
    "#     grid_gdf.to_csv(GRID_DATA_PATH, sep=\",\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "\n",
    "# def create_save_positives(incident_gdf, building_gdf, grid_gdf):\n",
    "#     incident_gdf.Date = pd.to_datetime(incident_gdf.Date)\n",
    "#     # Pick necessary columns\n",
    "#     incident_sub_gdf = incident_gdf[RF_INCIDENT_COLUMNS]\n",
    "\n",
    "#     grid_gdf['grid_id'] = grid_gdf.index #?\n",
    "#     grid_sub_gdf = grid_gdf[RF_GRID_COLUMNS]\n",
    "\n",
    "#     building_gdf = building_gdf.rename(columns={\"id\" : \"building_id\"})\n",
    "#     building_sub_gdf = building_gdf[RF_BUILDING_COLUMNS]\n",
    "#     positive_samples = grid_sub_gdf.merge(incident_sub_gdf, on='grid_id', how='inner')\n",
    "#     positive_samples.to_csv(POSITIVE_SAMPLES_PATH, sep=\",\", encoding=\"utf-8\", index=False)\n",
    "#     return positive_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def verify_sample(\n",
    "#     incidents,\n",
    "#     grid_id,\n",
    "#     date,\n",
    "#     window = DATE_WINDOW\n",
    "# ):\n",
    "#     start_date = date - pd.DateOffset(days=window)\n",
    "#     end_date = date + pd.DateOffset(days=window)\n",
    "\n",
    "#     grids = incidents[(incidents['Date'] >= start_date) & (incidents['Date'] <= end_date)].values\n",
    "\n",
    "#     return False if grid_id not in grids else True\n",
    "\n",
    "\n",
    "# def create_save_negatives(\n",
    "#     positives,\n",
    "#     incidents,\n",
    "#     grid\n",
    "# ):\n",
    "#     grids_with_building = list(grid[grid.has_building == True].grid_id.values)\n",
    "#     negatives = positives[['Date', 'Hour']]\n",
    "#     negatives[RF_GRID_COLUMNS] = None\n",
    "\n",
    "#     for i, row in negatives.iterrows():\n",
    "#         random_grid = random.sample(grids_with_building, 1)[0]\n",
    "#         while(verify_sample(incidents, random_grid, row.Date)):\n",
    "#             random_grid = random.sample(grids_with_building, 1)[0]\n",
    "#         grid_data = grid[grid.grid_id == random_grid][RF_GRID_COLUMNS].reset_index(drop=True)\n",
    "#         negatives.loc[i, RF_GRID_COLUMNS] = grid_data.iloc[0]\n",
    "#     # save\n",
    "#     negatives.to_csv(NEGATIVE_SAMPLES_PATH, sep=\",\", encoding=\"utf-8\", index=False)\n",
    "#     return negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.GetWeather import GetWeather\n",
    "\n",
    "# incident_df = pd.read_csv(INCIDENT_DATA_PATH, sep=\",\", encoding=\"utf-8\")\n",
    "# #incident_df = incident_df.drop(['Unnamed: 0'], axis=1)\n",
    "# incident_df = incident_df.set_index('Incident_ID')\n",
    "\n",
    "# # create datasets\n",
    "# building_df = pd.read_csv(BOUWJAAR_DATA_PATH, sep=\";\", encoding=\"utf-8\")\n",
    "# building_df['WKT_LNG_LAT'] = building_df['WKT_LNG_LAT'].apply(loads)\n",
    "# building_df['WKT_LAT_LNG'] = building_df['WKT_LAT_LNG'].apply(loads)\n",
    "\n",
    "# incidents_weather_df = pd.read_csv(INCIDENTS_WEATHER_PATH, sep=\",\", encoding=\"utf-8\")\n",
    "# grid_gdf = create_grid_gdf()\n",
    "\n",
    "# incidents_weather_df = incidents_weather_df[~incidents_weather_df.Service_Area.isin(SERVICE_AREAS_OUT_OF_SCOPE)]\n",
    "# df_tree_incidents = incident_df[incident_df[\"Damage_Type\"]==\"Building\"]\n",
    "# building_gdf, incident_gdf = create_building_incident_gdf(incidents_weather_df=incidents_weather_df, buildings=building_df, grid_gdf=grid_gdf)\n",
    "\n",
    "# # get rid of unnecessary columns\n",
    "# building_gdf = building_gdf[BUILDING_COLUMNS]\n",
    "# grid_gdf, building_gdf = enrich_grid_df(grid_gdf=grid_gdf, building_gdf=building_gdf)\n",
    "\n",
    "# # save data\n",
    "# save_data(building_gdf=building_gdf, incident_gdf=incident_gdf, grid_gdf=grid_gdf)\n",
    "\n",
    "# positive_samples = create_save_positives(incident_gdf=incident_gdf, building_gdf=building_gdf, grid_gdf=grid_gdf)\n",
    "# negative_samples = create_save_negatives(positives=positive_samples, incidents=incident_gdf, grid=grid_gdf)\n",
    "\n",
    "# weather_getter = GetWeather(grid_path=GRID_DATA_PATH, samples_path=NEGATIVE_SAMPLES_PATH, sleep_time=90)  \n",
    "# negative_samples = weather_getter.add_weather_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from geopy.geocoders import Nominatim\n",
    "from tqdm import tqdm\n",
    "from geopy.distance import geodesic\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import math\n",
    "import datetime\n",
    "import geopandas as gpd\n",
    "import urllib.request\n",
    "import requests\n",
    "import json\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "from shapely.geometry import Polygon, Point\n",
    "from retry_requests import retry\n",
    "from shapely.wkt import loads\n",
    "import random \n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_GEBOUWEN = Path(\"src/data_gebouwen\")\n",
    "DATA_DIR_BOMEN = Path(\"src/data_bomen\")\n",
    "BOUWJAAR_DATA_PATH = DATA_DIR_GEBOUWEN / 'BOUWJAAR.csv'\n",
    "INCIDENT_DATA_PATH = DATA_DIR_GEBOUWEN / 'Building_incident_with_weather_data.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_BOMEN = Path(\"src/data_bomen\")\n",
    "DATA_DIR_GEBOUWEN = Path(\"src/data_gebouwen\")\n",
    "\n",
    "INCIDENT_DATA_PATH = DATA_DIR_BOMEN / 'Incidenten_oorspronkelijk_volledig.csv'\n",
    "BOUWJAAR_DATA_PATH = DATA_DIR_GEBOUWEN / 'BOUWJAAR.csv'\n",
    "ZIPCODE_JSON_PATH = DATA_DIR_BOMEN / \"zipcodes_boxes.json\"\n",
    "GRID_SIZE = 200     ## GRID SIZE IN METERS\n",
    "\n",
    "BUILDING_DATA_CLEAN_PATH = DATA_DIR_GEBOUWEN / f\"building_geo_data_clean_{str(GRID_SIZE)}.csv\"\n",
    "GRID_DATA_PATH = DATA_DIR_GEBOUWEN / f\"grid_enriched_buildings_{GRID_SIZE}.csv\"\n",
    "INCIDENTS_WEATHER_PATH = DATA_DIR_GEBOUWEN / \"Building_incident_with_weather_data.csv\"\n",
    "INCIDENTS_WEATHER_GEO_PATH = DATA_DIR_GEBOUWEN / f\"incidents_weather_geo_buildings_{GRID_SIZE}.csv\"\n",
    "\n",
    "POSITIVE_SAMPLES_PATH = DATA_DIR_GEBOUWEN / f\"positive_samples_buildings_{GRID_SIZE}.csv\"\n",
    "NEGATIVE_SAMPLES_PATH = DATA_DIR_GEBOUWEN / f\"negative_samples_buildings_{GRID_SIZE}.csv\"\n",
    "\n",
    "ZIP_KEY = \"Zipcode\"\n",
    "ZIP4_KEY = \"Zip4\"\n",
    "\n",
    "DATE_WINDOW = 7\n",
    "\n",
    "AMSTERDAM_BBOX = (52.26618, 4.64663, 52.475115999999994, 5.150491999999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUILDING_COLUMNS = [\n",
    "    \"OBJECTNUMMER\",\n",
    "    \"grid_id\",\n",
    "    \"Bouwjaar\",       \n",
    "    \"WKT_LNG_LAT\",\n",
    "    \"WKT_LAT_LNG\",\n",
    "    \"LNG\",\n",
    "    \"LAT\"\n",
    "]\n",
    "\n",
    "SERVICE_AREAS_OUT_OF_SCOPE = [\n",
    "    \"Amstelveen\",\n",
    "    \"Aalsmeer\",\n",
    "    \"Uithoorn\"\n",
    "]\n",
    "\n",
    "RF_INCIDENT_COLUMNS = [\n",
    "    \"Incident_ID\",\n",
    "    \"Service_Area\",\n",
    "    \"grid_id\",\n",
    "    \"Date\",\n",
    "    \"Hour\",\n",
    "    \"temperature_2m\",\n",
    "    \"relative_humidity_2m\",\n",
    "    \"dew_point_2m\",\n",
    "    \"apparent_temperature\",\n",
    "    \"precipitation\",\n",
    "    \"rain\",\n",
    "    \"snowfall\",\n",
    "    \"snow_depth\",\n",
    "    \"weather_code\",\n",
    "    \"pressure_msl\",\n",
    "    \"surface_pressure\",\n",
    "    \"wind_speed_10m\",\n",
    "    \"wind_direction_10m\",\n",
    "    \"wind_gusts_10m\",\n",
    "    \"soil_temperature_0_to_7cm\",\n",
    "    \"soil_temperature_7_to_28cm\",\n",
    "    \"soil_temperature_28_to_100cm\",\n",
    "    \"soil_temperature_100_to_255cm\",\n",
    "    \"soil_moisture_0_to_7cm\",\n",
    "    \"soil_moisture_7_to_28cm\",\n",
    "    \"soil_moisture_28_to_100cm\",\n",
    "    \"soil_moisture_100_to_255cm\",\n",
    "]\n",
    "\n",
    "RF_GRID_COLUMNS = [\n",
    "    \"grid_id\",\n",
    "    \"has_building\",\n",
    "    \"Bouwjaar\",\n",
    "]\n",
    "\n",
    "RF_BUILDING_COLUMNS = [\n",
    "    \"OBJECTNUMMER\",\n",
    "    \"Bouwjaar\",       \n",
    "    \"WKT_LNG_LAT\",\n",
    "    \"WKT_LAT_LNG\",\n",
    "    \"LNG\",\n",
    "    \"LAT\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid_gdf():\n",
    "    #geolocator = Nominatim(user_agent=\"user_agent\")\n",
    "\n",
    "    # Get coordinates for Amsterdam\n",
    "    #location = geolocator.geocode(\"Amsterdam, Netherlands\")\n",
    "    # amsterdam_lat, amsterdam_lon = location.latitude, location.longitude\n",
    "    amsterdam_lat, amsterdam_lon = [4.88, 52.32]\n",
    "\n",
    "    amsterdam_bbox = AMSTERDAM_BBOX\n",
    "\n",
    "    # Calculate grid bounds\n",
    "    lat_step = GRID_SIZE / 111000  # 1 degree of latitude is approximately 111 kilometers\n",
    "    lon_step = (GRID_SIZE / 111000) / np.cos(np.radians(amsterdam_lat))  # Correct for latitude\n",
    "\n",
    "    grid_polygons = []\n",
    "    for lat in np.arange(amsterdam_bbox[0], amsterdam_bbox[2], lat_step):\n",
    "        for lon in np.arange(amsterdam_bbox[1], amsterdam_bbox[3], lon_step):\n",
    "            polygon = Polygon([\n",
    "                (lon, lat),\n",
    "                (lon + lon_step, lat),\n",
    "                (lon + lon_step, lat + lat_step),\n",
    "                (lon, lat + lat_step),\n",
    "                (lon, lat),\n",
    "            ])\n",
    "            grid_polygons.append(polygon)\n",
    "\n",
    "    grid_gdf = gpd.GeoDataFrame(geometry=grid_polygons, crs=\"EPSG:4326\")\n",
    "    return grid_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_building_incident_gdf(incidents_weather_df, buildings, grid_gdf):\n",
    "    # Filter on areas in scope\n",
    "    incidents_weather_df = incidents_weather_df[~incidents_weather_df.Service_Area.isin(SERVICE_AREAS_OUT_OF_SCOPE)]\n",
    "\n",
    "    # create gdf from buildings\n",
    "    building_gdf = gpd.GeoDataFrame(buildings, geometry=gpd.points_from_xy(buildings['LNG'], buildings['LAT']), crs=\"EPSG:4326\")\n",
    "    # create gdf from indicents\n",
    "    incident_gdf = gpd.GeoDataFrame(incidents_weather_df, geometry=gpd.points_from_xy(incidents_weather_df['LON'], incidents_weather_df['LAT']), crs=\"EPSG:4326\")\n",
    "    #join with grid gdf\n",
    "    building_gdf = gpd.sjoin(building_gdf, grid_gdf, how=\"left\", op=\"within\")\n",
    "    incident_gdf = gpd.sjoin(incident_gdf, grid_gdf, how=\"left\", op=\"within\")\n",
    "\n",
    "    #clean up gdf\n",
    "    building_gdf = building_gdf.rename(columns={\"index_right\" : \"grid_id\", \"geometry\" : \"location\"})\n",
    "    incident_gdf = incident_gdf.rename(columns={\"index_right\" : \"grid_id\", \"geometry\" : \"location\"})\n",
    "\n",
    "    return building_gdf, incident_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cat_to_avg(\n",
    "    cat_values,\n",
    "    delimeter = \"-\"\n",
    "):\n",
    "    ''' \n",
    "    Converts categorical values to means of type float\n",
    "    Splits cat values on delimter, computes the mean for each cat\n",
    "    Returns mean of all means of the categories\n",
    "    '''\n",
    "    means = []\n",
    "    for cat in cat_values:\n",
    "        if not isinstance(cat, str):\n",
    "            continue\n",
    "        if not delimeter in cat:\n",
    "            continue\n",
    "        vals = cat.split(delimeter)\n",
    "        means.append(np.mean([float(val) for val in vals]))\n",
    "    m = round(np.mean(means), 3)\n",
    "    return 0 if np.isnan(m) else m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_grid_df(\n",
    "    grid_gdf,\n",
    "    building_gdf\n",
    "):\n",
    "    for i in grid_gdf.index:\n",
    "        building_sub_df = building_gdf[building_gdf.grid_id == i]\n",
    "        if len(building_sub_df)>0:\n",
    "            # Compute and add averages for height, diameter and year\n",
    "            grid_gdf.at[i, \"Bouwjaar\"] = round(np.mean(building_sub_df.Bouwjaar.values), 3)\n",
    "            # Add soortnaam counts\n",
    "            # for name, count in building_sub_df.soortnaamKort.value_counts().items():\n",
    "            #     grid_gdf.at[i, \"has_building\"] = True\n",
    "            #     grid_gdf.at[i, name] = count\n",
    "        else:\n",
    "            grid_gdf.at[i, \"has_building\"] = False\n",
    "\n",
    "    return grid_gdf, building_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(building_gdf, incident_gdf, grid_gdf):\n",
    "    # save data\n",
    "    building_gdf.to_csv(BUILDING_DATA_CLEAN_PATH, sep=\",\", encoding=\"utf-8\", index=False)\n",
    "    incident_gdf.to_csv(INCIDENTS_WEATHER_GEO_PATH, sep=\",\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "    # clean and save data\n",
    "    grid_gdf = grid_gdf.fillna(0)\n",
    "    grid_gdf[grid_gdf.has_building == True]\n",
    "    grid_gdf['grid_id'] = grid_gdf.index\n",
    "    grid_gdf.to_csv(GRID_DATA_PATH, sep=\",\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "\n",
    "def create_save_positives(incident_gdf, building_gdf, grid_gdf):\n",
    "    incident_gdf.Date = pd.to_datetime(incident_gdf.Date)\n",
    "    # Pick necessary columns\n",
    "    incident_sub_gdf = incident_gdf[RF_INCIDENT_COLUMNS]\n",
    "\n",
    "    grid_gdf['grid_id'] = grid_gdf.index #?\n",
    "    grid_sub_gdf = grid_gdf[RF_GRID_COLUMNS]\n",
    "\n",
    "    building_gdf = building_gdf.rename(columns={\"id\" : \"building_id\"})\n",
    "    building_sub_gdf = building_gdf[RF_BUILDING_COLUMNS]\n",
    "    positive_samples = grid_sub_gdf.merge(incident_sub_gdf, on='grid_id', how='inner')\n",
    "    positive_samples.to_csv(POSITIVE_SAMPLES_PATH, sep=\",\", encoding=\"utf-8\", index=False)\n",
    "    return positive_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_sample(\n",
    "    incidents,\n",
    "    grid_id,\n",
    "    date,\n",
    "    window = DATE_WINDOW\n",
    "):\n",
    "    start_date = date - pd.DateOffset(days=window)\n",
    "    end_date = date + pd.DateOffset(days=window)\n",
    "\n",
    "    grids = incidents[(incidents['Date'] >= start_date) & (incidents['Date'] <= end_date)].values\n",
    "\n",
    "    return False if grid_id not in grids else True\n",
    "\n",
    "\n",
    "def create_save_negatives(\n",
    "    positives,\n",
    "    incidents,\n",
    "    grid\n",
    "):\n",
    "    grids_with_building = list(grid[grid.has_building == True].grid_id.values)\n",
    "    negatives = positives[['Date', 'Hour']]\n",
    "    negatives[RF_GRID_COLUMNS] = None\n",
    "\n",
    "    for i, row in negatives.iterrows():\n",
    "        random_grid = random.sample(grids_with_building, 1)[0]\n",
    "        while(verify_sample(incidents, random_grid, row.Date)):\n",
    "            random_grid = random.sample(grids_with_building, 1)[0]\n",
    "        grid_data = grid[grid.grid_id == random_grid][RF_GRID_COLUMNS].reset_index(drop=True)\n",
    "        negatives.loc[i, RF_GRID_COLUMNS] = grid_data.iloc[0]\n",
    "    # save\n",
    "    negatives.to_csv(NEGATIVE_SAMPLES_PATH, sep=\",\", encoding=\"utf-8\", index=False)\n",
    "    return negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aliha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:3526: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\Aliha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:3526: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\Aliha\\AppData\\Local\\Temp\\ipykernel_21508\\575692110.py:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'False' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  grid_gdf.at[i, \"has_building\"] = False\n",
      "C:\\Users\\Aliha\\AppData\\Local\\Temp\\ipykernel_21508\\2615208476.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  negatives[RF_GRID_COLUMNS] = None\n",
      "C:\\Users\\Aliha\\AppData\\Local\\Temp\\ipykernel_21508\\2615208476.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  negatives[RF_GRID_COLUMNS] = None\n",
      "C:\\Users\\Aliha\\AppData\\Local\\Temp\\ipykernel_21508\\2615208476.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  negatives[RF_GRID_COLUMNS] = None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m save_data(building_gdf\u001b[38;5;241m=\u001b[39mbuilding_gdf, incident_gdf\u001b[38;5;241m=\u001b[39mincident_gdf, grid_gdf\u001b[38;5;241m=\u001b[39mgrid_gdf)\n\u001b[0;32m     26\u001b[0m positive_samples \u001b[38;5;241m=\u001b[39m create_save_positives(incident_gdf\u001b[38;5;241m=\u001b[39mincident_gdf, building_gdf\u001b[38;5;241m=\u001b[39mbuilding_gdf, grid_gdf\u001b[38;5;241m=\u001b[39mgrid_gdf)\n\u001b[1;32m---> 27\u001b[0m negative_samples \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_save_negatives\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositives\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositive_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincidents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mincident_gdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrid_gdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m weather_getter \u001b[38;5;241m=\u001b[39m GetWeather(grid_path\u001b[38;5;241m=\u001b[39mGRID_DATA_PATH, samples_path\u001b[38;5;241m=\u001b[39mNEGATIVE_SAMPLES_PATH, sleep_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m90\u001b[39m)  \n\u001b[0;32m     30\u001b[0m negative_samples \u001b[38;5;241m=\u001b[39m weather_getter\u001b[38;5;241m.\u001b[39madd_weather_data()\n",
      "Cell \u001b[1;32mIn[11], line 25\u001b[0m, in \u001b[0;36mcreate_save_negatives\u001b[1;34m(positives, incidents, grid)\u001b[0m\n\u001b[0;32m     22\u001b[0m negatives[RF_GRID_COLUMNS] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m negatives\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m---> 25\u001b[0m     random_grid \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrids_with_building\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m(verify_sample(incidents, random_grid, row\u001b[38;5;241m.\u001b[39mDate)):\n\u001b[0;32m     27\u001b[0m         random_grid \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(grids_with_building, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.240.0_x64__qbz5n2kfra8p0\\Lib\\random.py:430\u001b[0m, in \u001b[0;36mRandom.sample\u001b[1;34m(self, population, k, counts)\u001b[0m\n\u001b[0;32m    428\u001b[0m randbelow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m k \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n:\n\u001b[1;32m--> 430\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample larger than population or is negative\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    431\u001b[0m result \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m k\n\u001b[0;32m    432\u001b[0m setsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m21\u001b[39m        \u001b[38;5;66;03m# size of a small set minus size of an empty list\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "from src.GetWeather import GetWeather\n",
    "\n",
    "incident_df = pd.read_csv(INCIDENT_DATA_PATH, sep=\",\", encoding=\"utf-8\")\n",
    "#incident_df = incident_df.drop(['Unnamed: 0'], axis=1)\n",
    "incident_df = incident_df.set_index('Incident_ID')\n",
    "\n",
    "# create datasets\n",
    "building_df = pd.read_csv(BOUWJAAR_DATA_PATH, sep=\";\", encoding=\"utf-8\")\n",
    "building_df['WKT_LNG_LAT'] = building_df['WKT_LNG_LAT'].apply(loads)\n",
    "building_df['WKT_LAT_LNG'] = building_df['WKT_LAT_LNG'].apply(loads)\n",
    "\n",
    "incidents_weather_df = pd.read_csv(INCIDENTS_WEATHER_PATH, sep=\",\", encoding=\"utf-8\")\n",
    "grid_gdf = create_grid_gdf()\n",
    "\n",
    "incidents_weather_df = incidents_weather_df[~incidents_weather_df.Service_Area.isin(SERVICE_AREAS_OUT_OF_SCOPE)]\n",
    "df_tree_incidents = incident_df[incident_df[\"Damage_Type\"]==\"Building\"]\n",
    "building_gdf, incident_gdf = create_building_incident_gdf(incidents_weather_df=incidents_weather_df, buildings=building_df, grid_gdf=grid_gdf)\n",
    "\n",
    "# get rid of unnecessary columns\n",
    "building_gdf = building_gdf[BUILDING_COLUMNS]\n",
    "grid_gdf, building_gdf = enrich_grid_df(grid_gdf=grid_gdf, building_gdf=building_gdf)\n",
    "\n",
    "# save data\n",
    "save_data(building_gdf=building_gdf, incident_gdf=incident_gdf, grid_gdf=grid_gdf)\n",
    "\n",
    "positive_samples = create_save_positives(incident_gdf=incident_gdf, building_gdf=building_gdf, grid_gdf=grid_gdf)\n",
    "negative_samples = create_save_negatives(positives=positive_samples, incidents=incident_gdf, grid=grid_gdf)\n",
    "\n",
    "weather_getter = GetWeather(grid_path=GRID_DATA_PATH, samples_path=NEGATIVE_SAMPLES_PATH, sleep_time=90)  \n",
    "negative_samples = weather_getter.add_weather_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
